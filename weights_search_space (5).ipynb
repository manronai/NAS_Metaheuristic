{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uqf5K66myHbk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "\n",
        "# List of PyTorch optimizers\n",
        "optimizers = [\n",
        "    optim.SGD,               # Stochastic Gradient Descent\n",
        "    optim.Adam,              # Adam optimizer\n",
        "    optim.AdamW,             # AdamW optimizer\n",
        "    optim.Adagrad,           # Adagrad optimizer\n",
        "    optim.Adadelta,          # Adadelta optimizer\n",
        "    optim.RMSprop,           # RMSprop optimizer\n",
        "    optim.Adamax,            # Adamax optimizer\n",
        "    optim.ASGD,              # Averaged Stochastic Gradient Descent\n",
        "    optim.LBFGS,             # Limited-memory BFGS\n",
        "    optim.Rprop,             # Resilient backpropagation\n",
        "    optim.SparseAdam,        # Sparse Adam optimizer\n",
        "    optim.NAdam,             # Nesterov-accelerated Adaptive Moment Estimation\n",
        "    optim.RAdam,             # Rectified Adam optimizer\n",
        "]\n",
        "def train_model(model, train_data, train_labels, epochs=10, learning_rate=0.001, optim_index=1):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_labels = train_labels.view(-1, 1)\n",
        "    # Define loss function and optimizer\n",
        "    criterion = torch.nn.BCELoss()  # Use BCE for binary output (CrossEntropy if multiple classes)\n",
        "    optimizer = optimizers[optim_index](model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    dataset = TensorDataset(train_data, train_labels)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            # Zero gradients from the previous step\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        super(FFN, self).__init__()\n",
        "        layers = []\n",
        "        sizes = [input_size] + hidden_sizes\n",
        "\n",
        "        for i in range(len(sizes) - 1):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "            if i < len(sizes) -  1:  # No activation for the final layer\n",
        "                layers.append(nn.ReLU())\n",
        "        layers.append(nn.Linear(sizes[-1], 1))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def get_parameters(self):\n",
        "        \"\"\"Retrieve all model parameters as a list of tensors.\"\"\"\n",
        "        return [p.clone().detach() for p in self.parameters()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"Set model parameters from a list of tensors.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            for param, new_param in zip(self.parameters(), parameters):\n",
        "                param.copy_(new_param)\n",
        "    def extract_features(self, x):\n",
        "        \"\"\"Get the feature representation from the last hidden layer\"\"\"\n",
        "        _, features = self.forward(x, return_features=True)\n",
        "        return features[-1]  # Return the last hidden layer activation\n",
        "\n",
        "# Create an initial population of 20 FFNs\n",
        "population = [FFN(98, [20, 15], 2) for _ in range(20)]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_dataset(dataset_name):\n",
        "  fairness_to_select = None\n",
        "  if dataset_name == 'compas':\n",
        "\n",
        "    import pandas as pd\n",
        "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "    from sklearn.compose import ColumnTransformer\n",
        "    from sklearn.pipeline import Pipeline\n",
        "\n",
        "    # URL to the COMPAS dataset\n",
        "    url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
        "\n",
        "    # Load the dataset\n",
        "    df_compas = pd.read_csv(url)\n",
        "    \"\"\"\n",
        "    # Display the first few rows of the dataset\n",
        "\n",
        "\n",
        "    # Identify categorical columns\n",
        "    categorical_columns = df_compas.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    # Initialize the LabelEncoder and OneHotEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    one_hot_encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "\n",
        "    # Apply Label Encoding to binary categorical columns\n",
        "    binary_categorical_cols = ['sex', 'score_text']  # Example binary columns\n",
        "    for col in binary_categorical_cols:\n",
        "        if col in categorical_columns:\n",
        "            df_compas[col] = label_encoder.fit_transform(df_compas[col])\n",
        "\n",
        "    # Apply One-Hot Encoding to other categorical columns\n",
        "    other_categorical_cols = [col for col in categorical_columns if col not in binary_categorical_cols]\n",
        "\n",
        "    # Use ColumnTransformer to apply one-hot encoding\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('onehot', one_hot_encoder, other_categorical_cols)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    # Apply the transformations\n",
        "    df_compas_encoded = preprocessor.fit_transform(df_compas)\n",
        "\n",
        "    # Convert the result to a DataFrame\n",
        "    df_compas_encoded = pd.DataFrame(df_compas_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "    # Display the first few rows of the encoded dataset\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    df_compas = df_compas.drop('id',  axis=1)\n",
        "    df_compas = df_compas.drop('dob',  axis=1)\n",
        "    df_compas = df_compas.drop('compas_screening_date',  axis=1)\n",
        "    df_compas = df_compas.drop('c_case_number',  axis=1)\n",
        "    df_compas = df_compas.drop('screening_date', axis=1)\n",
        "    df_compas = df_compas.drop('in_custody', axis=1)\n",
        "    df_compas = df_compas.drop('out_custody', axis=1)\n",
        "    df_compas = df_compas.drop('v_screening_date', axis=1)\n",
        "    df_compas = df_compas.drop('c_offense_date', axis=1)\n",
        "    df_compas = df_compas.drop('c_jail_out', axis=1)\n",
        "    df_compas = df_compas.drop('c_jail_in', axis=1)\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "    # Initialize the LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Apply Label Encoding to a specific column\n",
        "    df_compas['name'] = label_encoder.fit_transform(df_compas['name'])\n",
        "    df_compas['first'] = label_encoder.fit_transform(df_compas['first'])\n",
        "    df_compas['last'] = label_encoder.fit_transform(df_compas['last'])\n",
        "    df_compas['sex'] = label_encoder.fit_transform(df_compas['sex'])\n",
        "    df_compas['score_text'] = label_encoder.fit_transform(df_compas['score_text'])\n",
        "    df_compas['v_type_of_assessment'] = label_encoder.fit_transform(df_compas['v_type_of_assessment'])\n",
        "    df_compas['c_charge_desc'] = label_encoder.fit_transform(df_compas['c_charge_desc'])\n",
        "\n",
        "    df_compas['r_case_number'] = label_encoder.fit_transform(df_compas['r_case_number'])\n",
        "    df_compas['c_arrest_date'] = label_encoder.fit_transform(df_compas['c_arrest_date'])\n",
        "    df_compas['r_charge_degree'] = label_encoder.fit_transform(df_compas['r_charge_degree'])\n",
        "    df_compas['vr_case_number'] = label_encoder.fit_transform(df_compas['vr_case_number'])\n",
        "    df_compas['vr_charge_degree'] = label_encoder.fit_transform(df_compas['vr_charge_degree'])\n",
        "    df_compas['vr_offense_date'] = label_encoder.fit_transform(df_compas['vr_offense_date'])\n",
        "    df_compas['vr_charge_desc'] = label_encoder.fit_transform(df_compas['vr_charge_desc'])\n",
        "    df_compas['r_offense_date'] = label_encoder.fit_transform(df_compas['r_offense_date'])\n",
        "    df_compas['r_charge_desc'] = label_encoder.fit_transform(df_compas['r_charge_desc'])\n",
        "    df_compas['r_jail_in'] = label_encoder.fit_transform(df_compas['r_jail_in'])\n",
        "    df_compas['r_jail_out'] = label_encoder.fit_transform(df_compas['r_jail_out'])\n",
        "\n",
        "    import pandas as pd\n",
        "    df_compas_encoded = pd.get_dummies(df_compas, columns = ['age_cat', 'race', 'c_charge_degree', 'type_of_assessment', 'v_score_text'])\n",
        "\n",
        "    df_compas_encoded = df_compas_encoded.fillna(0)\n",
        "\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X = df_compas_encoded.drop(['two_year_recid'], axis=1)\n",
        "    y = df_compas_encoded['two_year_recid']\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    #print(X_test.columns)\n",
        "    # Convert to PyTorch tensors\n",
        "    X_train_tensor = torch.tensor(np.vstack(X_train.values).astype(np.float64), dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(np.vstack(X_test.values).astype(np.float64), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "    input_size = X_train_tensor.shape[1]\n",
        "    output_size = 2\n",
        "    fairness_to_select = 1\n",
        "  else :\n",
        "\n",
        "    from sklearn.datasets import fetch_openml\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    # Fetch UCI Adult Income Dataset\n",
        "    data = fetch_openml(\"adult\", version=2, as_frame=True)\n",
        "    df = data.frame\n",
        "    #print((df.columns))\n",
        "\n",
        "    # Encode target labels ('<=50K' or '>50K')\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['income'] = label_encoder.fit_transform(df['class'])\n",
        "    #print((df['income']))\n",
        "\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    # Convert boolean columns to integers (0 for False, 1 for True)\n",
        "    df = df.apply(lambda x: x.astype(int) if x.dtype == 'bool' else x)\n",
        "\n",
        "    # The rest remains unchanged\n",
        "\n",
        "    df = pd.get_dummies(df, drop_first=True)\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    X = df.drop(['income', 'class_>50K'], axis=1)\n",
        "    y = df['income']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    # Convert to PyTorch tensors\n",
        "    X_train_tensor = torch.tensor(np.vstack(X_train.values).astype(np.float32), dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(np.vstack(X_test.values).astype(np.float32), dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "    input_size = X_train_tensor.shape[1]\n",
        "    output_size = 2\n",
        "    fairness_to_select = 0\n",
        "  return X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, X_test, input_size, output_size, fairness_to_select"
      ],
      "metadata": {
        "id": "5ricOG9wyJgW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def fgsm_attack(model, data, target, epsilon):\n",
        "    \"\"\"Generates adversarial examples using FGSM.\"\"\"\n",
        "    data.requires_grad = True\n",
        "    output = model(data)\n",
        "    loss = F.binary_cross_entropy(output, target)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    perturbed_data = data + epsilon * data.grad.sign()\n",
        "    return torch.clamp(perturbed_data, 0, 1)\n",
        "\n",
        "def adversarial_train(model, X_train_tensor, y_train_tensor, optimizer, device, epsilon=0.1, attack_type='fgsm'):\n",
        "    \"\"\"Performs adversarial training using FGSM.\"\"\"\n",
        "\n",
        "    model.train()\n",
        "    epochs = 10\n",
        "    for epoch in range(epochs):\n",
        "      epoch_loss = 0.0\n",
        "      X_train_tensor, y_train_tensor = X_train_tensor.to(device), y_train_tensor.to(device)\n",
        "      y_train_tensor = y_train_tensor.view(-1, 1)\n",
        "      # Generate adversarial examples\n",
        "      if attack_type == 'fgsm':\n",
        "          adv_data = fgsm_attack(model, X_train_tensor, y_train_tensor, epsilon)\n",
        "      else:\n",
        "          adv_data = X_train_tensor  # Placeholder for PGD (can be implemented later)\n",
        "\n",
        "      # Combine clean and adversarial examples\n",
        "      mixed_data = torch.cat([X_train_tensor, adv_data])\n",
        "      mixed_target = torch.cat([y_train_tensor, y_train_tensor])\n",
        "\n",
        "      # Forward pass\n",
        "      optimizer.zero_grad()\n",
        "      output = model(mixed_data)\n",
        "      loss = F.binary_cross_entropy(output, mixed_target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "QOMiezzREsdU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "def compute_class_features(model, X, y, num_classes):\n",
        "    class_features = {i: [] for i in range(num_classes)}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(X)):\n",
        "            features = model.extract_features(X[i].unsqueeze(0))\n",
        "            class_features[y[i].item()].append(features)\n",
        "\n",
        "    # Compute mean feature representation for each class\n",
        "    for cls in class_features:\n",
        "        if class_features[cls]:  # Avoid empty class\n",
        "            class_features[cls] = torch.mean(torch.stack(class_features[cls]), dim=0)\n",
        "\n",
        "    return class_features\n",
        "\n",
        "def cafa_attack(model, X, y, target_class_features, epsilon=0.1):\n",
        "    X_adv = X.clone().detach().requires_grad_(True)\n",
        "\n",
        "    # Get original feature representation\n",
        "    features = model.extract_features(X_adv)\n",
        "\n",
        "    # Compute the feature shift direction towards target class\n",
        "    target_features = target_class_features[y.item()]\n",
        "    loss = torch.nn.functional.mse_loss(features, target_features)\n",
        "\n",
        "    # Compute gradient and generate adversarial example\n",
        "    loss.backward()\n",
        "    X_adv = X_adv - epsilon * X_adv.grad.sign()\n",
        "    return X_adv.detach()\n",
        "\n",
        "def compute_accuracy(model, X_test, y_test):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_test)\n",
        "        #_, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    #return accuracy_score(y_test.numpy(), predictions.numpy())\n",
        "    return ((outputs > 0.5).float() == y_test).float().mean()\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def pgd_adversarial_attack(model, X, y, epsilon=1, alpha=0.01, num_iter=40):\n",
        "    \"\"\"\n",
        "    Projected Gradient Descent (PGD) attack.\n",
        "\n",
        "    Args:\n",
        "        model: The target model to attack.\n",
        "        X: Input data (requires gradients).\n",
        "        y: Correct labels for the input data.\n",
        "        epsilon: Maximum allowed perturbation per input dimension.\n",
        "        alpha: Step size for each iteration.\n",
        "        num_iter: Number of iterations for the attack.\n",
        "\n",
        "    Returns:\n",
        "        Adversarial examples generated from X.\n",
        "    \"\"\"\n",
        "    # Clone input and set it to require gradients\n",
        "    X_adv = X.clone().detach().requires_grad_(True)\n",
        "    loss_fn = nn.BCELoss()\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        # Zero the gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass and compute loss\n",
        "        output = model(X_adv)\n",
        "        loss = loss_fn(output, y)\n",
        "        loss.backward()\n",
        "\n",
        "        # Update adversarial examples with the gradient sign\n",
        "        perturbation = alpha * X_adv.grad.sign()\n",
        "        X_adv = X_adv + perturbation\n",
        "\n",
        "        # Project back to the epsilon ball around the original inputs\n",
        "        X_adv = torch.max(torch.min(X_adv, X + epsilon), X - epsilon)\n",
        "        X_adv = torch.clamp(X_adv, 0, 1)  # Keep pixel values between 0 and 1\n",
        "\n",
        "        # Reset gradient computation\n",
        "        X_adv = X_adv.detach().requires_grad_(True)\n",
        "\n",
        "    return X_adv\n",
        "\n",
        "def fgsm_attack(model, X, y, epsilon):\n",
        "    X.requires_grad_()  # Ensure gradients are computed\n",
        "    model.zero_grad()  # Clear previous gradients\n",
        "    output = model(X)\n",
        "    loss = nn.BCELoss()(output, y)\n",
        "    loss.backward()\n",
        "    perturbation = epsilon * X.grad.sign()\n",
        "    X_adv = torch.clamp(X + perturbation, 0, 1)\n",
        "    return X_adv\n",
        "def adversarial_attack_test_data(model, X, y, attack_name):\n",
        "  if attack_name == 'PGD':\n",
        "    X_adv = pgd_adversarial_attack(model, X, y)\n",
        "  else:\n",
        "    X_adv = fgsm_attack(model, X, y, 0.05)\n",
        "  return X_adv\n",
        "def adversarial_attack_accuracy(model, X, y, attack_name):\n",
        "  if attack_name == 'PGD':\n",
        "    X_adv = pgd_adversarial_attack(model, X, y)\n",
        "    rslt = compute_accuracy(model, X_adv, y)\n",
        "  else:\n",
        "    X_adv = fgsm_attack(model, X, y, 0.05)\n",
        "    rslt = compute_accuracy(model, X_adv, y)\n",
        "  return rslt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def compute_tpr_fpr(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "\n",
        "    # Compute TPR and FPR\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "\n",
        "    return tpr, fpr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, sensitive_feature):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_test_tensor)\n",
        "        predictions = (outputs > 0.5).float()  # Assuming binary classification with threshold 0.5\n",
        "\n",
        "    # Convert sensitive_feature to torch tensor if it isn't already\n",
        "    sensitive_feature_tensor = torch.tensor(sensitive_feature.values, dtype=torch.int32)\n",
        "\n",
        "    # Calculate true positive rates (TPR) and false positive rates (FPR) for each group\n",
        "    tpr_group_0 = ((predictions[sensitive_feature_tensor == 0] == 1) & (y_test_tensor[sensitive_feature_tensor == 0] == 1)).float().mean().item()\n",
        "    tpr_group_1 = ((predictions[sensitive_feature_tensor == 1] == 1) & (y_test_tensor[sensitive_feature_tensor == 1] == 1)).float().mean().item()\n",
        "\n",
        "    fpr_group_0 = ((predictions[sensitive_feature_tensor == 0] == 1) & (y_test_tensor[sensitive_feature_tensor == 0] == 0)).float().mean().item()\n",
        "    fpr_group_1 = ((predictions[sensitive_feature_tensor == 1] == 1) & (y_test_tensor[sensitive_feature_tensor == 1] == 0)).float().mean().item()\n",
        "\n",
        "    # Compute equalized odds difference\n",
        "    tpr_difference = abs(tpr_group_0 - tpr_group_1)\n",
        "    fpr_difference = abs(fpr_group_0 - fpr_group_1)\n",
        "\n",
        "    equalized_odds_difference = max(tpr_difference, fpr_difference)\n",
        "\n",
        "    return tpr_difference, fpr_difference\n",
        "\n",
        "# Example usage\n",
        "# Assuming you have a model, test data, and sensitive feature\n",
        "# model = ...\n",
        "# X_test_tensor = ...\n",
        "# y_test_tensor = ...\n",
        "# sensitive_feature = ...\n",
        "\n",
        "# equalized_odds_diff = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, sensitive_feature)\n",
        "# print(\"Equalized Odds Difference:\", equalized_odds_diff)\n",
        "\n"
      ],
      "metadata": {
        "id": "hJ-aKSxayY0a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "def calculate_metrics_sk(model, X_test_tensor, y_test_tensor):\n",
        "    # Convert predictions to binary (0 or 1) using a threshold of 0.5\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_test_tensor)\n",
        "    y_pred = (outputs > 0.5).float()\n",
        "\n",
        "    y_true_np = y_test_tensor.numpy()\n",
        "    y_pred_np = y_pred.numpy()\n",
        "    precision = precision_score(y_true_np, y_pred_np)\n",
        "    recall = recall_score(y_true_np, y_pred_np)\n",
        "    f1 = f1_score(y_true_np, y_pred_np)\n",
        "    return precision, recall, f1\n",
        "def calculate_metrics(model, X_test_tensor, y_test_tensor):\n",
        "    # Convert predictions to binary (0 or 1) using a threshold of 0.5\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_test_tensor)\n",
        "    y_pred = (outputs > 0.5).float()\n",
        "    y_true = y_test_tensor\n",
        "    # Calculate True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
        "    # Calculate True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
        "    TP = ((y_pred == 1) & (y_true == 1)).sum().item()\n",
        "    FP = ((y_pred == 1) & (y_true == 0)).sum().item()\n",
        "    FN = ((y_pred == 0) & (y_true == 1)).sum().item()\n",
        "\n",
        "    # Calculate Precision, Recall, and F1-Score\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return precision, recall, f1_score\n"
      ],
      "metadata": {
        "id": "lExtRvMB-Wju"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor,X_test, input_size, output_size, fairness_to_select = select_dataset('compas')\n",
        "y_train_tensor = y_train_tensor.view(-1, 1)\n",
        "y_test_tensor = y_test_tensor.view(-1, 1)\n",
        "sensetive_features = [['sex_Male', 'race_Black', 'race_White'], ['sex',  'race_African-American', 'race_Asian']]"
      ],
      "metadata": {
        "id": "Y-tKB7wGciw8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FFN(input_size, [10, 8], 2)"
      ],
      "metadata": {
        "id": "kNG2vjNcFykL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, X_train_tensor, y_train_tensor, 20, 0.014043171929277431)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hth-P26qE3U_",
        "outputId": "cb1aee1f-16ab-4742-ef07-fbf19a63e366"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 190.5865\n",
            "Epoch 2/20, Loss: 29.3727\n",
            "Epoch 3/20, Loss: 24.3434\n",
            "Epoch 4/20, Loss: 24.4862\n",
            "Epoch 5/20, Loss: 21.9655\n",
            "Epoch 6/20, Loss: 22.5664\n",
            "Epoch 7/20, Loss: 21.2915\n",
            "Epoch 8/20, Loss: 21.0440\n",
            "Epoch 9/20, Loss: 21.2390\n",
            "Epoch 10/20, Loss: 20.9917\n",
            "Epoch 11/20, Loss: 21.5201\n",
            "Epoch 12/20, Loss: 20.9377\n",
            "Epoch 13/20, Loss: 21.1960\n",
            "Epoch 14/20, Loss: 18.9735\n",
            "Epoch 15/20, Loss: 19.8763\n",
            "Epoch 16/20, Loss: 18.1009\n",
            "Epoch 17/20, Loss: 21.4593\n",
            "Epoch 18/20, Loss: 19.3664\n",
            "Epoch 19/20, Loss: 23.9865\n",
            "Epoch 20/20, Loss: 19.3329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(compute_accuracy(model, X_test_tensor, y_test_tensor))\n",
        "print(calculate_metrics_sk(model, X_test_tensor, y_test_tensor))"
      ],
      "metadata": {
        "id": "HT1CxEFQ_BRj",
        "outputId": "deedc54a-c8e0-4449-b9f0-a90aae56a070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9764)\n",
            "(0.9621451104100947, 0.9838709677419355, 0.9728867623604466)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_adv = adversarial_attack_test_data(model, X_test_tensor, y_test_tensor, 'FGSM')\n",
        "print(compute_accuracy(model, X_adv, y_test_tensor))\n",
        "print(calculate_metrics_sk(model, X_adv, y_test_tensor))"
      ],
      "metadata": {
        "id": "oSVTjopCKZ1z",
        "outputId": "5798fc86-afbc-484d-c118-ae455723f64b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4297)\n",
            "(0.42966042966042967, 1.0, 0.6010664081434803)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = FFN(input_size, [9, 10, 5], 2)\n",
        "adversarial_train(model, X_train_tensor, y_train_tensor, optim.Adam(model.parameters(), lr=0.001), 'cpu', epsilon=0.1, attack_type='pgd')\n",
        "adversarial_train(model, X_train_tensor, y_train_tensor, optim.Adam(model.parameters(), lr=0.001), 'cpu', epsilon=0.2, attack_type='fgsm')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8aZ87Dvenxt",
        "outputId": "614d1353-9807-4f90-ebfb-090300b713af"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0961\n",
            "Epoch 2/10, Loss: 0.0924\n",
            "Epoch 3/10, Loss: 0.0902\n",
            "Epoch 4/10, Loss: 0.0892\n",
            "Epoch 5/10, Loss: 0.0891\n",
            "Epoch 6/10, Loss: 0.0894\n",
            "Epoch 7/10, Loss: 0.0901\n",
            "Epoch 8/10, Loss: 0.0904\n",
            "Epoch 9/10, Loss: 0.0901\n",
            "Epoch 10/10, Loss: 0.0895\n",
            "Epoch 1/10, Loss: 1.7542\n",
            "Epoch 2/10, Loss: 1.7443\n",
            "Epoch 3/10, Loss: 1.7349\n",
            "Epoch 4/10, Loss: 1.7254\n",
            "Epoch 5/10, Loss: 1.7157\n",
            "Epoch 6/10, Loss: 1.7061\n",
            "Epoch 7/10, Loss: 1.6966\n",
            "Epoch 8/10, Loss: 1.6872\n",
            "Epoch 9/10, Loss: 1.6777\n",
            "Epoch 10/10, Loss: 1.6684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(adversarial_attack_accuracy(model, X_test_tensor, y_test_tensor, 'FGSM'))\n",
        "adv_test = adversarial_attack_test_data(model, X_test_tensor, y_test_tensor, 'FGSM')\n",
        "print(calculate_metrics_sk(model, adv_test, y_test_tensor))"
      ],
      "metadata": {
        "id": "UZf7wgCGFaK2",
        "outputId": "97509984-fb4f-4702-cdb9-f5932a6e9932",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4297)\n",
            "(0.42966042966042967, 1.0, 0.6010664081434803)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1vQQ98Yh8Hc",
        "outputId": "d13523e5-0473-4f30-fc9d-71bdbde30d40"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5703)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_attack_accuracy(model, X_test_tensor, y_test_tensor, 'PGD')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOzUK84TJkM6",
        "outputId": "9b21ad8d-081c-4a38-80de-280345fd3007"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2571)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymoo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXrcjy9DyY6g",
        "outputId": "064bff44-9044-4a4a-bbdb-fa98ecb18b2f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymoo\n",
            "  Downloading pymoo-0.6.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from pymoo) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pymoo) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from pymoo) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.11/dist-packages (from pymoo) (1.7.0)\n",
            "Collecting cma==3.2.2 (from pymoo)\n",
            "  Downloading cma-3.2.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting alive-progress (from pymoo)\n",
            "  Downloading alive_progress-3.2.0-py3-none-any.whl.metadata (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from pymoo)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from pymoo) (1.2.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo) (2.8.2)\n",
            "Collecting about-time==4.2.1 (from alive-progress->pymoo)\n",
            "  Downloading about_time-4.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting grapheme==0.6.0 (from alive-progress->pymoo)\n",
            "  Downloading grapheme-0.6.0.tar.gz (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->pymoo) (1.17.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n",
            "Downloading pymoo-0.6.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cma-3.2.2-py2.py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alive_progress-3.2.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading about_time-4.2.1-py3-none-any.whl (13 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: grapheme\n",
            "  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grapheme: filename=grapheme-0.6.0-py3-none-any.whl size=210082 sha256=39d634814fb03a1765c1d6524ffbd2f45079fd3162fa5038e10a7ee58713fc2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/3b/0b/1b865800e916d671a24028d884698674138632a83fdfad4926\n",
            "Successfully built grapheme\n",
            "Installing collected packages: grapheme, dill, cma, about-time, alive-progress, pymoo\n",
            "Successfully installed about-time-4.2.1 alive-progress-3.2.0 cma-3.2.2 dill-0.3.9 grapheme-0.6.0 pymoo-0.6.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.core.variable import Real\n",
        "from pymoo.termination import get_termination\n",
        "import random\n",
        "import numpy as np\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "from pymoo.operators.crossover.sbx import SBX\n",
        "from pymoo.operators.mutation.pm import PM\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.termination import get_termination\n",
        "from pymoo.core.callback import Callback\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class FFNProblem(Problem):\n",
        "    def __init__(self, max_layers, max_nodes, X_train, X_test, y_train, y_test):\n",
        "        super().__init__(n_var=max_layers+2,\n",
        "                         n_obj=4,\n",
        "                         n_constr=1,\n",
        "                         xl=5,\n",
        "                         xu=max_nodes,\n",
        "                         type_var=int)\n",
        "        self.max_layers = max_layers\n",
        "        self.max_nodes = max_nodes\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "        self.count = 0\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        adversarial_accuracy_PGD = np.zeros(x.shape[0])\n",
        "        adversarial_accuracy_FGSM = np.zeros(x.shape[0])\n",
        "        equalized_odds_gender = np.zeros(x.shape[0])\n",
        "        equalized_odds_race_Black = np.zeros(x.shape[0])\n",
        "        equalized_odds_race_White = np.zeros(x.shape[0])\n",
        "        self.count += 1\n",
        "        print(self.count)\n",
        "        print(x)\n",
        "        for i, architecture in enumerate(x):\n",
        "            l, learning_rate_and_ind_opt = architecture[:-2], architecture[-2:]\n",
        "\n",
        "\n",
        "            learning_rate = learning_rate_and_ind_opt[0]\n",
        "            ind_opt = int(learning_rate_and_ind_opt[1])\n",
        "            lr = 10 ** (-1*float(learning_rate))\n",
        "            print(lr, ind_opt)\n",
        "            l = np.round(l).astype(int)\n",
        "            print(l)\n",
        "            temp = l.tolist()\n",
        "            print(input_size)\n",
        "            model = FFN(input_size, temp, 2)\n",
        "\n",
        "            #train_model(model, X_train_tensor, y_train_tensor, 5, lr, ind_opt)\n",
        "            adversarial_train(model, X_train_tensor, y_train_tensor, optim.Adam(model.parameters(), lr=0.001), 'cpu', epsilon=0.2, attack_type='pgd')\n",
        "            #adversarial_train(model, X_train_tensor, y_train_tensor, optim.Adam(model.parameters(), lr=0.001), 'cpu', epsilon=0.2, attack_type='fgsm')\n",
        "\n",
        "            #adv_acc, eq_odds = evaluate_model(architecture, self.X_train, self.X_test, self.y_train, self.y_test)\n",
        "            accuracy_pgd = adversarial_attack_accuracy(model, X_test_tensor, y_test_tensor, 'PGD')\n",
        "            accuracy_fgsm = adversarial_attack_accuracy(model, X_test_tensor, y_test_tensor, 'FGSM')\n",
        "            tpr_diff_gender, fpr_diff_gender = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, X_test[sensetive_features[fairness_to_select][0]])\n",
        "            tpr_diff_race_Black, fpr_diff_race_Black = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, X_test[sensetive_features[fairness_to_select][1]])\n",
        "            tpr_diff_race_White, fpr_diff_race_White = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, X_test[sensetive_features[fairness_to_select][2]])\n",
        "\n",
        "            equalized_odd_gender = (tpr_diff_gender + fpr_diff_gender) / 2\n",
        "            equalized_odd_race_Black = (tpr_diff_race_Black + fpr_diff_race_Black) / 2\n",
        "            equalized_odd_race_White = (tpr_diff_race_White + fpr_diff_race_White) / 2\n",
        "\n",
        "            adversarial_accuracy_PGD[i] = accuracy_pgd\n",
        "            adversarial_accuracy_FGSM[i] = accuracy_fgsm\n",
        "\n",
        "            equalized_odds_gender[i] = equalized_odd_gender\n",
        "            equalized_odds_race_Black[i] = equalized_odd_race_Black\n",
        "            equalized_odds_race_White[i] = equalized_odd_race_White\n",
        "        out[\"G\"] = np.column_stack([ 0.4- adversarial_accuracy_PGD])\n",
        "        out[\"F\"] = np.column_stack([adversarial_accuracy_PGD, equalized_odds_gender, equalized_odds_race_Black, equalized_odds_race_White])\n",
        "\n",
        "\n",
        "# Initialize the problem\n",
        "max_layers = 2  # Example: maximum number of layers\n",
        "max_nodes = 50  # Example: maximum number of nodes per layer\n",
        "problem = FFNProblem(max_layers, max_nodes, X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor)\n",
        "\n",
        "# Define crossover and mutation operators\n",
        "crossover = SBX(prob=0.9, eta=15)\n",
        "mutation = PM(eta=20)\n",
        "\n",
        "# Initialize the algorithm\n",
        "#algorithm = NSGA2(pop_size=10, sampling=np.array(population))\n",
        "\n",
        "l = []\n",
        "\n",
        "for _ in range(4):\n",
        "  pp = []\n",
        "  for i in range(4):\n",
        "    if i > 1:\n",
        "      pp.append(random.randint(1, 7))\n",
        "    else :\n",
        "\n",
        "      pp.append(random.randint(5, 50))\n",
        "\n",
        "  l.append(pp)\n",
        "initial_population = np.array(l)\n",
        "# Initialize the algorithm with the custom initial population\n",
        "algorithm = NSGA2(\n",
        "    pop_size=4,\n",
        "    sampling = initial_population,\n",
        "    crossover=crossover,\n",
        "    mutation=mutation,\n",
        "    eliminate_duplicates=True\n",
        ")\n",
        "\n",
        "# Set the initial population\n",
        "\n",
        "\n",
        "\n",
        "# Define the termination criterion\n",
        "termination = get_termination(\"n_gen\", 10)\n",
        "\n",
        "# Run the optimization\n",
        "res = minimize(problem,\n",
        "               algorithm,\n",
        "               termination,\n",
        "               verbose=True)\n",
        "\n",
        "# Print the results\n",
        "print()\n",
        "print(\"Best G for PGD found: %s\" % res.G)\n",
        "print()\n",
        "print(\"Best solution found: %s\" % res.F)\n",
        "print()\n",
        "print(\"Best architecture found: %s\" % res.X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCS7pzFnyZAW",
        "outputId": "d4111c42-131f-450c-e51b-76bcb23cce44"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[[11 27  7  3]\n",
            " [43 21  7  1]\n",
            " [34 39  1  4]\n",
            " [10 40  3  7]]\n",
            "1e-07 3\n",
            "[11 27]\n",
            "51\n",
            "Epoch 1/10, Loss: 54.4100\n",
            "Epoch 2/10, Loss: 54.4100\n",
            "Epoch 3/10, Loss: 54.4100\n",
            "Epoch 4/10, Loss: 54.4100\n",
            "Epoch 5/10, Loss: 54.4100\n",
            "Epoch 6/10, Loss: 54.4100\n",
            "Epoch 7/10, Loss: 54.4100\n",
            "Epoch 8/10, Loss: 54.4100\n",
            "Epoch 9/10, Loss: 54.4100\n",
            "Epoch 10/10, Loss: 54.4100\n",
            "1e-07 1\n",
            "[43 21]\n",
            "51\n",
            "Epoch 1/10, Loss: 13.7758\n",
            "Epoch 2/10, Loss: 10.9944\n",
            "Epoch 3/10, Loss: 9.2522\n",
            "Epoch 4/10, Loss: 7.4100\n",
            "Epoch 5/10, Loss: 5.8142\n",
            "Epoch 6/10, Loss: 4.6107\n",
            "Epoch 7/10, Loss: 3.4582\n",
            "Epoch 8/10, Loss: 2.4733\n",
            "Epoch 9/10, Loss: 1.8914\n",
            "Epoch 10/10, Loss: 1.4796\n",
            "0.1 4\n",
            "[34 39]\n",
            "51\n",
            "Epoch 1/10, Loss: 54.4515\n",
            "Epoch 2/10, Loss: 54.4170\n",
            "Epoch 3/10, Loss: 54.4104\n",
            "Epoch 4/10, Loss: 54.4100\n",
            "Epoch 5/10, Loss: 54.4100\n",
            "Epoch 6/10, Loss: 54.4100\n",
            "Epoch 7/10, Loss: 54.4100\n",
            "Epoch 8/10, Loss: 54.4100\n",
            "Epoch 9/10, Loss: 54.4100\n",
            "Epoch 10/10, Loss: 54.4100\n",
            "0.001 7\n",
            "[10 40]\n",
            "51\n",
            "Epoch 1/10, Loss: 44.9670\n",
            "Epoch 2/10, Loss: 38.8739\n",
            "Epoch 3/10, Loss: 30.5766\n",
            "Epoch 4/10, Loss: 22.2803\n",
            "Epoch 5/10, Loss: 16.9363\n",
            "Epoch 6/10, Loss: 13.2439\n",
            "Epoch 7/10, Loss: 10.2030\n",
            "Epoch 8/10, Loss: 7.9026\n",
            "Epoch 9/10, Loss: 5.8968\n",
            "Epoch 10/10, Loss: 3.7463\n",
            "==========================================================================================\n",
            "n_gen  |  n_eval  | n_nds  |     cv_min    |     cv_avg    |      eps      |   indicator  \n",
            "==========================================================================================\n",
            "     1 |        4 |      3 |  0.000000E+00 |  0.0974012475 |             - |             -\n",
            "2\n",
            "[[11.         27.          5.90541251 16.2325621 ]\n",
            " [11.         27.          7.          5.        ]\n",
            " [43.         20.          7.          5.        ]\n",
            " [34.         39.          7.63158508  5.        ]]\n",
            "1.2433330822264297e-06 16\n",
            "[11 27]\n",
            "51\n",
            "Epoch 1/10, Loss: 13.2854\n",
            "Epoch 2/10, Loss: 10.8549\n",
            "Epoch 3/10, Loss: 8.4822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pymoo/operators/crossover/sbx.py:47: RuntimeWarning: invalid value encountered in power\n",
            "  betaq[mask] = np.power((rand * alpha), (1.0 / (eta + 1.0)))[mask]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Loss: 6.2131\n",
            "Epoch 5/10, Loss: 4.0676\n",
            "Epoch 6/10, Loss: 2.2480\n",
            "Epoch 7/10, Loss: 1.3069\n",
            "Epoch 8/10, Loss: 2.1088\n",
            "Epoch 9/10, Loss: 3.0633\n",
            "Epoch 10/10, Loss: 3.0561\n",
            "1e-07 5\n",
            "[11 27]\n",
            "51\n",
            "Epoch 1/10, Loss: 22.3425\n",
            "Epoch 2/10, Loss: 21.6446\n",
            "Epoch 3/10, Loss: 21.4742\n",
            "Epoch 4/10, Loss: 21.7775\n",
            "Epoch 5/10, Loss: 20.7845\n",
            "Epoch 6/10, Loss: 18.6372\n",
            "Epoch 7/10, Loss: 14.6554\n",
            "Epoch 8/10, Loss: 9.5269\n",
            "Epoch 9/10, Loss: 5.9726\n",
            "Epoch 10/10, Loss: 3.7047\n",
            "1e-07 5\n",
            "[43 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 4.2713\n",
            "Epoch 2/10, Loss: 4.0009\n",
            "Epoch 3/10, Loss: 1.9564\n",
            "Epoch 4/10, Loss: 2.7380\n",
            "Epoch 5/10, Loss: 2.0853\n",
            "Epoch 6/10, Loss: 1.1540\n",
            "Epoch 7/10, Loss: 1.1896\n",
            "Epoch 8/10, Loss: 1.4601\n",
            "Epoch 9/10, Loss: 1.4847\n",
            "Epoch 10/10, Loss: 1.3226\n",
            "2.3356885102365108e-08 5\n",
            "[34 39]\n",
            "51\n",
            "Epoch 1/10, Loss: 54.4100\n",
            "Epoch 2/10, Loss: 54.4100\n",
            "Epoch 3/10, Loss: 54.4100\n",
            "Epoch 4/10, Loss: 54.4100\n",
            "Epoch 5/10, Loss: 54.4100\n",
            "Epoch 6/10, Loss: 54.4100\n",
            "Epoch 7/10, Loss: 54.4100\n",
            "Epoch 8/10, Loss: 54.4100\n",
            "Epoch 9/10, Loss: 54.4100\n",
            "Epoch 10/10, Loss: 54.4100\n",
            "     2 |        8 |      2 |  0.000000E+00 |  0.000000E+00 |  0.2881719077 |         ideal\n",
            "3\n",
            "[[11.81342481 22.12043256  7.          5.        ]\n",
            " [42.95551315 21.27119834  7.          7.28484733]\n",
            " [11.         20.3131879   6.94028075 13.53035264]\n",
            " [43.26289932 27.6868121   5.96513176  5.        ]]\n",
            "1e-07 5\n",
            "[12 22]\n",
            "51\n",
            "Epoch 1/10, Loss: 15.8801\n",
            "Epoch 2/10, Loss: 14.9931\n",
            "Epoch 3/10, Loss: 12.9693\n",
            "Epoch 4/10, Loss: 10.9651\n",
            "Epoch 5/10, Loss: 9.3547\n",
            "Epoch 6/10, Loss: 7.9754\n",
            "Epoch 7/10, Loss: 6.7027\n",
            "Epoch 8/10, Loss: 5.5599\n",
            "Epoch 9/10, Loss: 4.5811\n",
            "Epoch 10/10, Loss: 3.8083\n",
            "1e-07 7\n",
            "[43 21]\n",
            "51\n",
            "Epoch 1/10, Loss: 10.2179\n",
            "Epoch 2/10, Loss: 5.6782\n",
            "Epoch 3/10, Loss: 6.6005\n",
            "Epoch 4/10, Loss: 8.5975\n",
            "Epoch 5/10, Loss: 5.3411\n",
            "Epoch 6/10, Loss: 2.1121\n",
            "Epoch 7/10, Loss: 1.6527\n",
            "Epoch 8/10, Loss: 1.8912\n",
            "Epoch 9/10, Loss: 1.9103\n",
            "Epoch 10/10, Loss: 1.7419\n",
            "1.1474116340902652e-07 13\n",
            "[11 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 28.8095\n",
            "Epoch 2/10, Loss: 27.7612\n",
            "Epoch 3/10, Loss: 27.7578\n",
            "Epoch 4/10, Loss: 27.4089\n",
            "Epoch 5/10, Loss: 26.6176\n",
            "Epoch 6/10, Loss: 25.4536\n",
            "Epoch 7/10, Loss: 23.9910\n",
            "Epoch 8/10, Loss: 22.3842\n",
            "Epoch 9/10, Loss: 20.8644\n",
            "Epoch 10/10, Loss: 19.5267\n",
            "1.0835981073418668e-06 5\n",
            "[43 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 41.3078\n",
            "Epoch 2/10, Loss: 39.0116\n",
            "Epoch 3/10, Loss: 36.2074\n",
            "Epoch 4/10, Loss: 32.8852\n",
            "Epoch 5/10, Loss: 28.9964\n",
            "Epoch 6/10, Loss: 25.6490\n",
            "Epoch 7/10, Loss: 23.1640\n",
            "Epoch 8/10, Loss: 19.2679\n",
            "Epoch 9/10, Loss: 15.8427\n",
            "Epoch 10/10, Loss: 12.5769\n",
            "     3 |       12 |      2 |  0.000000E+00 |  0.000000E+00 |  2.863417E+01 |         ideal\n",
            "4\n",
            "[[40.46175437 20.45374237  5.96513176  5.        ]\n",
            " [10.69504659 27.6868121   5.96513176 16.05810382]\n",
            " [11.98931242 27.54625763  6.94028075 13.53035264]\n",
            " [42.54241256 17.89451805  6.94028075  5.39121203]]\n",
            "1.0835981073418668e-06 5\n",
            "[40 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 54.4100\n",
            "Epoch 2/10, Loss: 54.4100\n",
            "Epoch 3/10, Loss: 54.4100\n",
            "Epoch 4/10, Loss: 54.4100\n",
            "Epoch 5/10, Loss: 54.4100\n",
            "Epoch 6/10, Loss: 54.4100\n",
            "Epoch 7/10, Loss: 54.4100\n",
            "Epoch 8/10, Loss: 54.4100\n",
            "Epoch 9/10, Loss: 54.4100\n",
            "Epoch 10/10, Loss: 54.4100\n",
            "1.0835981073418668e-06 16\n",
            "[11 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 16.9712\n",
            "Epoch 2/10, Loss: 15.4740\n",
            "Epoch 3/10, Loss: 14.6299\n",
            "Epoch 4/10, Loss: 14.0961\n",
            "Epoch 5/10, Loss: 14.8438\n",
            "Epoch 6/10, Loss: 15.1490\n",
            "Epoch 7/10, Loss: 13.5540\n",
            "Epoch 8/10, Loss: 9.9643\n",
            "Epoch 9/10, Loss: 6.3479\n",
            "Epoch 10/10, Loss: 4.0735\n",
            "1.1474116340902652e-07 13\n",
            "[12 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 52.2225\n",
            "Epoch 2/10, Loss: 50.8853\n",
            "Epoch 3/10, Loss: 49.5757\n",
            "Epoch 4/10, Loss: 47.8880\n",
            "Epoch 5/10, Loss: 45.9824\n",
            "Epoch 6/10, Loss: 43.3175\n",
            "Epoch 7/10, Loss: 40.3304\n",
            "Epoch 8/10, Loss: 37.4320\n",
            "Epoch 9/10, Loss: 34.7718\n",
            "Epoch 10/10, Loss: 31.7612\n",
            "1.1474116340902652e-07 5\n",
            "[43 18]\n",
            "51\n",
            "Epoch 1/10, Loss: 28.5572\n",
            "Epoch 2/10, Loss: 26.4062\n",
            "Epoch 3/10, Loss: 33.9029\n",
            "Epoch 4/10, Loss: 35.3600\n",
            "Epoch 5/10, Loss: 30.8012\n",
            "Epoch 6/10, Loss: 21.9699\n",
            "Epoch 7/10, Loss: 9.4361\n",
            "Epoch 8/10, Loss: 4.2140\n",
            "Epoch 9/10, Loss: 4.8818\n",
            "Epoch 10/10, Loss: 4.6658\n",
            "     4 |       16 |      2 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f\n",
            "5\n",
            "[[10.16353852 22.84039919  5.94196395  5.22558764]\n",
            " [44.95881186 27.6868121   5.47387332  5.27108036]\n",
            " [44.10418099 27.58613899  6.96344856 13.48361287]\n",
            " [ 9.90967359 18.38243005  6.94028075 13.43610602]]\n",
            "1.1429732041942226e-06 5\n",
            "[10 23]\n",
            "51\n",
            "Epoch 1/10, Loss: 13.2628\n",
            "Epoch 2/10, Loss: 11.3693\n",
            "Epoch 3/10, Loss: 9.6129\n",
            "Epoch 4/10, Loss: 8.0163\n",
            "Epoch 5/10, Loss: 6.6314\n",
            "Epoch 6/10, Loss: 5.4927\n",
            "Epoch 7/10, Loss: 4.6884\n",
            "Epoch 8/10, Loss: 4.3075\n",
            "Epoch 9/10, Loss: 4.6315\n",
            "Epoch 10/10, Loss: 5.7905\n",
            "3.358355611184009e-06 5\n",
            "[45 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 43.6050\n",
            "Epoch 2/10, Loss: 41.9605\n",
            "Epoch 3/10, Loss: 39.1968\n",
            "Epoch 4/10, Loss: 34.6964\n",
            "Epoch 5/10, Loss: 27.9190\n",
            "Epoch 6/10, Loss: 20.8460\n",
            "Epoch 7/10, Loss: 13.9976\n",
            "Epoch 8/10, Loss: 7.7443\n",
            "Epoch 9/10, Loss: 13.2641\n",
            "Epoch 10/10, Loss: 21.8167\n",
            "1.0878059666527118e-07 13\n",
            "[44 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 14.1542\n",
            "Epoch 2/10, Loss: 7.8085\n",
            "Epoch 3/10, Loss: 12.9759\n",
            "Epoch 4/10, Loss: 16.5859\n",
            "Epoch 5/10, Loss: 15.0620\n",
            "Epoch 6/10, Loss: 12.3250\n",
            "Epoch 7/10, Loss: 8.7811\n",
            "Epoch 8/10, Loss: 5.7832\n",
            "Epoch 9/10, Loss: 2.9990\n",
            "Epoch 10/10, Loss: 2.3458\n",
            "1.1474116340902652e-07 13\n",
            "[10 18]\n",
            "51\n",
            "Epoch 1/10, Loss: 54.2097\n",
            "Epoch 2/10, Loss: 54.2139\n",
            "Epoch 3/10, Loss: 54.2125\n",
            "Epoch 4/10, Loss: 54.2059\n",
            "Epoch 5/10, Loss: 54.2023\n",
            "Epoch 6/10, Loss: 54.2004\n",
            "Epoch 7/10, Loss: 54.1989\n",
            "Epoch 8/10, Loss: 54.1973\n",
            "Epoch 9/10, Loss: 54.1961\n",
            "Epoch 10/10, Loss: 54.1659\n",
            "     5 |       20 |      2 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f\n",
            "6\n",
            "[[10.37039447 20.35620307  6.94028075  5.48946632]\n",
            " [42.54241256 17.81756355  6.94028075  5.39121203]\n",
            " [44.47098715 17.85150288  6.94028075 13.46257269]\n",
            " [11.         20.39014241  6.94028075 13.53035264]]\n",
            "1.1474116340902652e-07 5\n",
            "[10 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 45.4743\n",
            "Epoch 2/10, Loss: 43.1267\n",
            "Epoch 3/10, Loss: 40.3523\n",
            "Epoch 4/10, Loss: 37.0957\n",
            "Epoch 5/10, Loss: 33.2896\n",
            "Epoch 6/10, Loss: 29.8720\n",
            "Epoch 7/10, Loss: 26.1040\n",
            "Epoch 8/10, Loss: 22.1896\n",
            "Epoch 9/10, Loss: 17.5971\n",
            "Epoch 10/10, Loss: 13.4581\n",
            "1.1474116340902652e-07 5\n",
            "[43 18]\n",
            "51\n",
            "Epoch 1/10, Loss: 25.4761\n",
            "Epoch 2/10, Loss: 25.7886\n",
            "Epoch 3/10, Loss: 26.3338\n",
            "Epoch 4/10, Loss: 26.4274\n",
            "Epoch 5/10, Loss: 25.9902\n",
            "Epoch 6/10, Loss: 25.4544\n",
            "Epoch 7/10, Loss: 24.9276\n",
            "Epoch 8/10, Loss: 24.5610\n",
            "Epoch 9/10, Loss: 24.3784\n",
            "Epoch 10/10, Loss: 24.3302\n",
            "1.1474116340902652e-07 13\n",
            "[44 18]\n",
            "51\n",
            "Epoch 1/10, Loss: 32.5437\n",
            "Epoch 2/10, Loss: 33.8483\n",
            "Epoch 3/10, Loss: 34.6796\n",
            "Epoch 4/10, Loss: 35.0833\n",
            "Epoch 5/10, Loss: 35.0589\n",
            "Epoch 6/10, Loss: 35.0716\n",
            "Epoch 7/10, Loss: 34.7919\n",
            "Epoch 8/10, Loss: 34.4118\n",
            "Epoch 9/10, Loss: 33.7577\n",
            "Epoch 10/10, Loss: 32.6089\n",
            "1.1474116340902652e-07 13\n",
            "[11 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 31.5953\n",
            "Epoch 2/10, Loss: 28.4427\n",
            "Epoch 3/10, Loss: 25.2154\n",
            "Epoch 4/10, Loss: 22.2547\n",
            "Epoch 5/10, Loss: 19.9860\n",
            "Epoch 6/10, Loss: 18.2923\n",
            "Epoch 7/10, Loss: 17.0237\n",
            "Epoch 8/10, Loss: 15.9118\n",
            "Epoch 9/10, Loss: 14.7115\n",
            "Epoch 10/10, Loss: 13.2076\n",
            "     6 |       24 |      3 |  0.000000E+00 |  0.000000E+00 |  0.8333334558 |         ideal\n",
            "7\n",
            "[[11.         25.59201856  6.94028075 13.53035264]\n",
            " [ 7.16041518 20.32595277  9.64588127 13.23751881]\n",
            " [11.         20.3116011   7.81550337 13.53035264]\n",
            " [43.32188566 27.6868121   5.96513176  5.46124812]]\n",
            "1.1474116340902652e-07 13\n",
            "[11 26]\n",
            "51\n",
            "Epoch 1/10, Loss: 54.4100\n",
            "Epoch 2/10, Loss: 54.4100\n",
            "Epoch 3/10, Loss: 54.4100\n",
            "Epoch 4/10, Loss: 54.4100\n",
            "Epoch 5/10, Loss: 54.4100\n",
            "Epoch 6/10, Loss: 54.4100\n",
            "Epoch 7/10, Loss: 54.4100\n",
            "Epoch 8/10, Loss: 54.4100\n",
            "Epoch 9/10, Loss: 54.4100\n",
            "Epoch 10/10, Loss: 54.4100\n",
            "2.2600535330030118e-10 13\n",
            "[ 7 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 37.7368\n",
            "Epoch 2/10, Loss: 36.2185\n",
            "Epoch 3/10, Loss: 34.4008\n",
            "Epoch 4/10, Loss: 32.3949\n",
            "Epoch 5/10, Loss: 30.3035\n",
            "Epoch 6/10, Loss: 28.1171\n",
            "Epoch 7/10, Loss: 25.8647\n",
            "Epoch 8/10, Loss: 23.6422\n",
            "Epoch 9/10, Loss: 21.5338\n",
            "Epoch 10/10, Loss: 19.6411\n",
            "1.5293138922308693e-08 13\n",
            "[11 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 37.6195\n",
            "Epoch 2/10, Loss: 36.2757\n",
            "Epoch 3/10, Loss: 34.8176\n",
            "Epoch 4/10, Loss: 33.3002\n",
            "Epoch 5/10, Loss: 31.6539\n",
            "Epoch 6/10, Loss: 30.0336\n",
            "Epoch 7/10, Loss: 28.3910\n",
            "Epoch 8/10, Loss: 26.6149\n",
            "Epoch 9/10, Loss: 25.0443\n",
            "Epoch 10/10, Loss: 23.7255\n",
            "1.0835981073418668e-06 5\n",
            "[43 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 21.1513\n",
            "Epoch 2/10, Loss: 21.4938\n",
            "Epoch 3/10, Loss: 17.5024\n",
            "Epoch 4/10, Loss: 12.3707\n",
            "Epoch 5/10, Loss: 10.4015\n",
            "Epoch 6/10, Loss: 10.1563\n",
            "Epoch 7/10, Loss: 7.3026\n",
            "Epoch 8/10, Loss: 3.8279\n",
            "Epoch 9/10, Loss: 3.6496\n",
            "Epoch 10/10, Loss: 3.6918\n",
            "     7 |       28 |      4 |  0.000000E+00 |  0.000000E+00 |  0.6544728254 |         ideal\n",
            "8\n",
            "[[41.62498852 27.6868121   5.96513176  5.12167251]\n",
            " [10.7900005  20.3131879   6.94028075 13.61090236]\n",
            " [ 7.01124256 20.32594006  8.02108031 13.23751881]\n",
            " [11.14917471 20.31320062  6.94028075 13.53035264]]\n",
            "1.0835981073418668e-06 5\n",
            "[42 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 32.6306\n",
            "Epoch 2/10, Loss: 16.9540\n",
            "Epoch 3/10, Loss: 9.1331\n",
            "Epoch 4/10, Loss: 5.1229\n",
            "Epoch 5/10, Loss: 3.2720\n",
            "Epoch 6/10, Loss: 2.5615\n",
            "Epoch 7/10, Loss: 2.0456\n",
            "Epoch 8/10, Loss: 1.7339\n",
            "Epoch 9/10, Loss: 1.5920\n",
            "Epoch 10/10, Loss: 1.5077\n",
            "1.1474116340902652e-07 13\n",
            "[11 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 17.2261\n",
            "Epoch 2/10, Loss: 15.3491\n",
            "Epoch 3/10, Loss: 13.7554\n",
            "Epoch 4/10, Loss: 12.1604\n",
            "Epoch 5/10, Loss: 10.8671\n",
            "Epoch 6/10, Loss: 9.9944\n",
            "Epoch 7/10, Loss: 9.6471\n",
            "Epoch 8/10, Loss: 10.4807\n",
            "Epoch 9/10, Loss: 12.1530\n",
            "Epoch 10/10, Loss: 14.9366\n",
            "9.526199940159838e-09 13\n",
            "[ 7 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 16.0872\n",
            "Epoch 2/10, Loss: 13.7584\n",
            "Epoch 3/10, Loss: 11.8666\n",
            "Epoch 4/10, Loss: 10.1413\n",
            "Epoch 5/10, Loss: 8.9148\n",
            "Epoch 6/10, Loss: 7.5436\n",
            "Epoch 7/10, Loss: 6.4231\n",
            "Epoch 8/10, Loss: 5.4412\n",
            "Epoch 9/10, Loss: 4.7262\n",
            "Epoch 10/10, Loss: 4.0825\n",
            "1.1474116340902652e-07 13\n",
            "[11 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 44.5322\n",
            "Epoch 2/10, Loss: 36.6157\n",
            "Epoch 3/10, Loss: 25.3192\n",
            "Epoch 4/10, Loss: 12.2005\n",
            "Epoch 5/10, Loss: 5.9896\n",
            "Epoch 6/10, Loss: 5.9533\n",
            "Epoch 7/10, Loss: 5.7222\n",
            "Epoch 8/10, Loss: 4.9443\n",
            "Epoch 9/10, Loss: 4.6256\n",
            "Epoch 10/10, Loss: 5.6770\n",
            "     8 |       32 |      4 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f\n",
            "9\n",
            "[[11.2843722  27.62606851  6.94028075 12.57185951]\n",
            " [42.15576071 20.32595277  9.64588127 13.23751881]\n",
            " [42.9798129  20.37393149 13.53413528  5.        ]\n",
            " [ 8.35454078 23.80335702  5.96513176  5.        ]]\n",
            "1.1474116340902652e-07 12\n",
            "[11 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 54.4128\n",
            "Epoch 2/10, Loss: 54.4106\n",
            "Epoch 3/10, Loss: 54.4100\n",
            "Epoch 4/10, Loss: 54.4100\n",
            "Epoch 5/10, Loss: 54.4100\n",
            "Epoch 6/10, Loss: 54.4100\n",
            "Epoch 7/10, Loss: 54.4100\n",
            "Epoch 8/10, Loss: 54.4100\n",
            "Epoch 9/10, Loss: 54.4100\n",
            "Epoch 10/10, Loss: 54.4100\n",
            "2.2600535330030118e-10 13\n",
            "[42 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 5.0240\n",
            "Epoch 2/10, Loss: 8.9415\n",
            "Epoch 3/10, Loss: 8.1453\n",
            "Epoch 4/10, Loss: 3.8357\n",
            "Epoch 5/10, Loss: 2.6536\n",
            "Epoch 6/10, Loss: 2.7833\n",
            "Epoch 7/10, Loss: 2.6141\n",
            "Epoch 8/10, Loss: 2.1912\n",
            "Epoch 9/10, Loss: 1.9677\n",
            "Epoch 10/10, Loss: 2.1627\n",
            "2.923241680355915e-14 5\n",
            "[43 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 54.4100\n",
            "Epoch 2/10, Loss: 54.4100\n",
            "Epoch 3/10, Loss: 54.4100\n",
            "Epoch 4/10, Loss: 54.4100\n",
            "Epoch 5/10, Loss: 54.4100\n",
            "Epoch 6/10, Loss: 54.4100\n",
            "Epoch 7/10, Loss: 54.4100\n",
            "Epoch 8/10, Loss: 54.4100\n",
            "Epoch 9/10, Loss: 54.4100\n",
            "Epoch 10/10, Loss: 54.4100\n",
            "1.0835981073418668e-06 5\n",
            "[ 8 24]\n",
            "51\n",
            "Epoch 1/10, Loss: 37.9422\n",
            "Epoch 2/10, Loss: 36.8164\n",
            "Epoch 3/10, Loss: 35.6778\n",
            "Epoch 4/10, Loss: 34.5649\n",
            "Epoch 5/10, Loss: 33.4686\n",
            "Epoch 6/10, Loss: 32.3582\n",
            "Epoch 7/10, Loss: 31.2313\n",
            "Epoch 8/10, Loss: 30.0635\n",
            "Epoch 9/10, Loss: 28.8499\n",
            "Epoch 10/10, Loss: 27.5830\n",
            "     9 |       36 |      4 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f\n",
            "10\n",
            "[[43.26289932 23.7355977   5.96513176  5.        ]\n",
            " [ 7.36219733 27.7372189   6.94028075 13.53035264]\n",
            " [ 8.35454078 27.75457141  5.7772873   5.        ]\n",
            " [43.37577085 20.2627811   5.81727942  5.        ]]\n",
            "1.0835981073418668e-06 5\n",
            "[43 24]\n",
            "51\n",
            "Epoch 1/10, Loss: 37.2645\n",
            "Epoch 2/10, Loss: 37.2796\n",
            "Epoch 3/10, Loss: 37.3098\n",
            "Epoch 4/10, Loss: 36.9701\n",
            "Epoch 5/10, Loss: 35.4300\n",
            "Epoch 6/10, Loss: 32.6285\n",
            "Epoch 7/10, Loss: 29.1703\n",
            "Epoch 8/10, Loss: 24.8137\n",
            "Epoch 9/10, Loss: 21.2121\n",
            "Epoch 10/10, Loss: 17.4741\n",
            "1.1474116340902652e-07 13\n",
            "[ 7 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.1509\n",
            "Epoch 2/10, Loss: 25.1463\n",
            "Epoch 3/10, Loss: 22.5110\n",
            "Epoch 4/10, Loss: 19.5811\n",
            "Epoch 5/10, Loss: 16.3001\n",
            "Epoch 6/10, Loss: 13.4192\n",
            "Epoch 7/10, Loss: 10.6073\n",
            "Epoch 8/10, Loss: 8.4187\n",
            "Epoch 9/10, Loss: 6.8259\n",
            "Epoch 10/10, Loss: 5.5501\n",
            "1.6699854903527884e-06 5\n",
            "[ 8 28]\n",
            "51\n",
            "Epoch 1/10, Loss: 54.4100\n",
            "Epoch 2/10, Loss: 54.4100\n",
            "Epoch 3/10, Loss: 54.4100\n",
            "Epoch 4/10, Loss: 54.4100\n",
            "Epoch 5/10, Loss: 54.4100\n",
            "Epoch 6/10, Loss: 54.4100\n",
            "Epoch 7/10, Loss: 54.4100\n",
            "Epoch 8/10, Loss: 54.4100\n",
            "Epoch 9/10, Loss: 54.4100\n",
            "Epoch 10/10, Loss: 54.4100\n",
            "1.5230725154526133e-06 5\n",
            "[43 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 48.4080\n",
            "Epoch 2/10, Loss: 40.8356\n",
            "Epoch 3/10, Loss: 31.6322\n",
            "Epoch 4/10, Loss: 18.6178\n",
            "Epoch 5/10, Loss: 5.4866\n",
            "Epoch 6/10, Loss: 4.4274\n",
            "Epoch 7/10, Loss: 4.2909\n",
            "Epoch 8/10, Loss: 3.8488\n",
            "Epoch 9/10, Loss: 4.3221\n",
            "Epoch 10/10, Loss: 5.0201\n",
            "    10 |       40 |      4 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f\n",
            "\n",
            "Best G for PGD found: [[-0.17033956]\n",
            " [-0.17033956]\n",
            " [-0.02203742]\n",
            " [-0.02966044]]\n",
            "\n",
            "Best solution found: [[0.57033956 0.         0.         0.        ]\n",
            " [0.57033956 0.         0.         0.        ]\n",
            " [0.42203742 0.01379379 0.01798368 0.054242  ]\n",
            " [0.42966044 0.00902766 0.03670899 0.04853964]]\n",
            "\n",
            "Best architecture found: [[ 8.35454078 23.80335702  5.96513176  5.        ]\n",
            " [ 7.16041518 20.32595277  9.64588127 13.23751881]\n",
            " [43.26289932 27.6868121   5.96513176  5.        ]\n",
            " [11.         20.3131879   6.94028075 13.53035264]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.core.variable import Real\n",
        "from pymoo.termination import get_termination\n",
        "import random\n",
        "import numpy as np\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "from pymoo.operators.crossover.sbx import SBX\n",
        "from pymoo.operators.mutation.pm import PM\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.termination import get_termination\n",
        "from pymoo.core.callback import Callback\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class FFNProblem(Problem):\n",
        "    def __init__(self, max_layers, max_nodes, X_train, X_test, y_train, y_test):\n",
        "        super().__init__(n_var=max_layers+2,\n",
        "                         n_obj=4,\n",
        "                         n_constr=1,\n",
        "                         xl=5,\n",
        "                         xu=max_nodes,\n",
        "                         type_var=int)\n",
        "        self.max_layers = max_layers\n",
        "        self.max_nodes = max_nodes\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "        self.count = 0\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        adversarial_accuracy_PGD = np.zeros(x.shape[0])\n",
        "        adversarial_accuracy_FGSM = np.zeros(x.shape[0])\n",
        "        equalized_odds_gender = np.zeros(x.shape[0])\n",
        "        equalized_odds_race_Black = np.zeros(x.shape[0])\n",
        "        equalized_odds_race_White = np.zeros(x.shape[0])\n",
        "        self.count += 1\n",
        "        print(self.count)\n",
        "        print(x)\n",
        "        for i, architecture in enumerate(x):\n",
        "            l, learning_rate_and_ind_opt = architecture[:-2], architecture[-2:]\n",
        "\n",
        "\n",
        "            learning_rate = learning_rate_and_ind_opt[0]\n",
        "            ind_opt = int(learning_rate_and_ind_opt[1])\n",
        "            lr = 10 ** (-1*float(learning_rate))\n",
        "            print(lr, ind_opt)\n",
        "            l = np.round(l).astype(int)\n",
        "            print(l)\n",
        "            temp = l.tolist()\n",
        "            print(input_size)\n",
        "            model = FFN(input_size, temp, 2)\n",
        "\n",
        "            #train_model(model, X_train_tensor, y_train_tensor, 5, lr, ind_opt)\n",
        "            #adversarial_train(model, X_train_tensor, y_train_tensor, optim.Adam(model.parameters(), lr=0.001), 'cpu', epsilon=0.2, attack_type='pgd')\n",
        "            adversarial_train(model, X_train_tensor, y_train_tensor, optim.Adam(model.parameters(), lr=0.001), 'cpu', epsilon=0.2, attack_type='fgsm')\n",
        "\n",
        "            #adv_acc, eq_odds = evaluate_model(architecture, self.X_train, self.X_test, self.y_train, self.y_test)\n",
        "            accuracy_pgd = adversarial_attack_accuracy(model, X_test_tensor, y_test_tensor, 'PGD')\n",
        "            accuracy_fgsm = adversarial_attack_accuracy(model, X_test_tensor, y_test_tensor, 'FGSM')\n",
        "            tpr_diff_gender, fpr_diff_gender = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, X_test[sensetive_features[fairness_to_select][0]])\n",
        "            tpr_diff_race_Black, fpr_diff_race_Black = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, X_test[sensetive_features[fairness_to_select][1]])\n",
        "            tpr_diff_race_White, fpr_diff_race_White = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, X_test[sensetive_features[fairness_to_select][2]])\n",
        "\n",
        "            equalized_odd_gender = (tpr_diff_gender + fpr_diff_gender) / 2\n",
        "            equalized_odd_race_Black = (tpr_diff_race_Black + fpr_diff_race_Black) / 2\n",
        "            equalized_odd_race_White = (tpr_diff_race_White + fpr_diff_race_White) / 2\n",
        "\n",
        "            #adversarial_accuracy_PGD[i] = accuracy_pgd\n",
        "            adversarial_accuracy_FGSM[i] = accuracy_fgsm\n",
        "\n",
        "            equalized_odds_gender[i] = equalized_odd_gender\n",
        "            equalized_odds_race_Black[i] = equalized_odd_race_Black\n",
        "            equalized_odds_race_White[i] = equalized_odd_race_White\n",
        "        out[\"G\"] = np.column_stack([ 0.4- adversarial_accuracy_FGSM])\n",
        "        out[\"F\"] = np.column_stack([ adversarial_accuracy_FGSM, equalized_odds_gender, equalized_odds_race_Black, equalized_odds_race_White])\n",
        "\n",
        "random.seed(42)\n",
        "# Initialize the problem\n",
        "max_layers = 2  # Example: maximum number of layers\n",
        "max_nodes = 50  # Example: maximum number of nodes per layer\n",
        "problem = FFNProblem(max_layers, max_nodes, X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor)\n",
        "\n",
        "# Define crossover and mutation operators\n",
        "crossover = SBX(prob=0.9, eta=15)\n",
        "mutation = PM(eta=20)\n",
        "\n",
        "# Initialize the algorithm\n",
        "#algorithm = NSGA2(pop_size=10, sampling=np.array(population))\n",
        "\n",
        "l = []\n",
        "\n",
        "for _ in range(4):\n",
        "  pp = []\n",
        "  for i in range(4):\n",
        "    if i > 1:\n",
        "      pp.append(random.randint(1, 7))\n",
        "    else :\n",
        "\n",
        "      pp.append(random.randint(5, 50))\n",
        "\n",
        "  l.append(pp)\n",
        "initial_population = np.array(l)\n",
        "# Initialize the algorithm with the custom initial population\n",
        "algorithm = NSGA2(\n",
        "    pop_size=4,\n",
        "    sampling = initial_population,\n",
        "    crossover=crossover,\n",
        "    mutation=mutation,\n",
        "    eliminate_duplicates=True\n",
        ")\n",
        "\n",
        "# Set the initial population\n",
        "\n",
        "\n",
        "\n",
        "# Define the termination criterion\n",
        "termination = get_termination(\"n_gen\", 10)\n",
        "\n",
        "# Run the optimization\n",
        "res = minimize(problem,\n",
        "               algorithm,\n",
        "               termination,\n",
        "               verbose=True)\n",
        "\n",
        "# Print the results\n",
        "print()\n",
        "print(\"Best G for FGSM found: %s\" % res.G)\n",
        "print()\n",
        "print(\"Best solution found: %s\" % res.F)\n",
        "print()\n",
        "print(\"Best architecture found: %s\" % res.X)"
      ],
      "metadata": {
        "id": "3A2k2ks-R7hN",
        "outputId": "106980a2-8109-48f1-f8c2-5f4fa619e9b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[[45 12  1  6]\n",
            " [22 20  2  2]\n",
            " [11 48  6  5]\n",
            " [10 42  4  1]]\n",
            "0.1 6\n",
            "[45 12]\n",
            "51\n",
            "Epoch 1/10, Loss: 17.0410\n",
            "Epoch 2/10, Loss: 10.9655\n",
            "Epoch 3/10, Loss: 6.8667\n",
            "Epoch 4/10, Loss: 4.2791\n",
            "Epoch 5/10, Loss: 2.9333\n",
            "Epoch 6/10, Loss: 2.2921\n",
            "Epoch 7/10, Loss: 1.9039\n",
            "Epoch 8/10, Loss: 1.6350\n",
            "Epoch 9/10, Loss: 1.3794\n",
            "Epoch 10/10, Loss: 1.1816\n",
            "0.01 2\n",
            "[22 20]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5551\n",
            "Epoch 2/10, Loss: 27.5538\n",
            "Epoch 3/10, Loss: 27.5528\n",
            "Epoch 4/10, Loss: 27.5520\n",
            "Epoch 5/10, Loss: 27.5513\n",
            "Epoch 6/10, Loss: 27.5507\n",
            "Epoch 7/10, Loss: 27.5428\n",
            "Epoch 8/10, Loss: 27.4974\n",
            "Epoch 9/10, Loss: 26.8492\n",
            "Epoch 10/10, Loss: 25.2673\n",
            "1e-06 5\n",
            "[11 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 12.1170\n",
            "Epoch 2/10, Loss: 9.1987\n",
            "Epoch 3/10, Loss: 6.2171\n",
            "Epoch 4/10, Loss: 3.9654\n",
            "Epoch 5/10, Loss: 3.6517\n",
            "Epoch 6/10, Loss: 7.6394\n",
            "Epoch 7/10, Loss: 8.3638\n",
            "Epoch 8/10, Loss: 5.4471\n",
            "Epoch 9/10, Loss: 2.9540\n",
            "Epoch 10/10, Loss: 2.0187\n",
            "0.0001 1\n",
            "[10 42]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5590\n",
            "Epoch 2/10, Loss: 27.5576\n",
            "Epoch 3/10, Loss: 27.5563\n",
            "Epoch 4/10, Loss: 27.5552\n",
            "Epoch 5/10, Loss: 27.5543\n",
            "Epoch 6/10, Loss: 27.5535\n",
            "Epoch 7/10, Loss: 27.5529\n",
            "Epoch 8/10, Loss: 27.5377\n",
            "Epoch 9/10, Loss: 27.4856\n",
            "Epoch 10/10, Loss: 27.3733\n",
            "==========================================================================================\n",
            "n_gen  |  n_eval  | n_nds  |     cv_min    |     cv_avg    |      eps      |   indicator  \n",
            "==========================================================================================\n",
            "     1 |        4 |      3 |  0.000000E+00 |  0.000000E+00 |             - |             -\n",
            "2\n",
            "[[11.         48.          5.          5.        ]\n",
            " [14.48782316 12.          5.          5.        ]\n",
            " [ 9.         43.3002684   6.          5.        ]\n",
            " [44.         47.          6.          5.        ]]\n",
            "1e-05 5\n",
            "[11 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 5.3209\n",
            "Epoch 2/10, Loss: 3.4293\n",
            "Epoch 3/10, Loss: 2.1464\n",
            "Epoch 4/10, Loss: 1.4633\n",
            "Epoch 5/10, Loss: 1.1242\n",
            "Epoch 6/10, Loss: 0.9328\n",
            "Epoch 7/10, Loss: 0.8571\n",
            "Epoch 8/10, Loss: 0.8536\n",
            "Epoch 9/10, Loss: 0.8864\n",
            "Epoch 10/10, Loss: 0.9233\n",
            "1e-05 5\n",
            "[14 12]\n",
            "51\n",
            "Epoch 1/10, Loss: 6.6546\n",
            "Epoch 2/10, Loss: 5.9013\n",
            "Epoch 3/10, Loss: 5.0970\n",
            "Epoch 4/10, Loss: 4.3332\n",
            "Epoch 5/10, Loss: 3.7734\n",
            "Epoch 6/10, Loss: 3.4681\n",
            "Epoch 7/10, Loss: 3.3496\n",
            "Epoch 8/10, Loss: 3.3400\n",
            "Epoch 9/10, Loss: 3.3281\n",
            "Epoch 10/10, Loss: 3.1659\n",
            "1e-06 5\n",
            "[ 9 43]\n",
            "51\n",
            "Epoch 1/10, Loss: 15.8270\n",
            "Epoch 2/10, Loss: 11.5140\n",
            "Epoch 3/10, Loss: 7.9947\n",
            "Epoch 4/10, Loss: 5.5098\n",
            "Epoch 5/10, Loss: 4.5162\n",
            "Epoch 6/10, Loss: 4.4192\n",
            "Epoch 7/10, Loss: 4.1749\n",
            "Epoch 8/10, Loss: 4.4747\n",
            "Epoch 9/10, Loss: 5.0059\n",
            "Epoch 10/10, Loss: 5.3976\n",
            "1e-06 5\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 14.8853\n",
            "Epoch 2/10, Loss: 11.5732\n",
            "Epoch 3/10, Loss: 8.4555\n",
            "Epoch 4/10, Loss: 5.8816\n",
            "Epoch 5/10, Loss: 5.4975\n",
            "Epoch 6/10, Loss: 9.0761\n",
            "Epoch 7/10, Loss: 10.7286\n",
            "Epoch 8/10, Loss: 10.6522\n",
            "Epoch 9/10, Loss: 9.4276\n",
            "Epoch 10/10, Loss: 7.7745\n",
            "     2 |        8 |      4 |  0.000000E+00 |  0.000000E+00 |  0.3647619808 |         ideal\n",
            "3\n",
            "[[10.02588087 47.35467352  5.          5.        ]\n",
            " [ 9.99413462 41.93155451  8.14502108  5.        ]\n",
            " [10.97411913 45.45345551  5.04460352  5.        ]\n",
            " [11.00586538 48.06839493  5.          5.        ]]\n",
            "1e-05 5\n",
            "[10 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5535\n",
            "Epoch 2/10, Loss: 27.5529\n",
            "Epoch 3/10, Loss: 27.5524\n",
            "Epoch 4/10, Loss: 27.5445\n",
            "Epoch 5/10, Loss: 27.3450\n",
            "Epoch 6/10, Loss: 26.8922\n",
            "Epoch 7/10, Loss: 26.0815\n",
            "Epoch 8/10, Loss: 24.8014\n",
            "Epoch 9/10, Loss: 23.2792\n",
            "Epoch 10/10, Loss: 21.4969\n",
            "7.1610865619130005e-09 5\n",
            "[10 42]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5555\n",
            "Epoch 2/10, Loss: 27.5547\n",
            "Epoch 3/10, Loss: 27.5539\n",
            "Epoch 4/10, Loss: 27.5533\n",
            "Epoch 5/10, Loss: 27.5528\n",
            "Epoch 6/10, Loss: 27.5522\n",
            "Epoch 7/10, Loss: 27.5517\n",
            "Epoch 8/10, Loss: 27.5512\n",
            "Epoch 9/10, Loss: 27.5507\n",
            "Epoch 10/10, Loss: 27.5502\n",
            "9.023945935410176e-06 5\n",
            "[11 45]\n",
            "51\n",
            "Epoch 1/10, Loss: 15.4102\n",
            "Epoch 2/10, Loss: 13.1313\n",
            "Epoch 3/10, Loss: 10.1816\n",
            "Epoch 4/10, Loss: 7.4461\n",
            "Epoch 5/10, Loss: 4.9404\n",
            "Epoch 6/10, Loss: 2.8912\n",
            "Epoch 7/10, Loss: 2.7194\n",
            "Epoch 8/10, Loss: 5.2683\n",
            "Epoch 9/10, Loss: 5.1501\n",
            "Epoch 10/10, Loss: 3.7342\n",
            "1e-05 5\n",
            "[11 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 13.2598\n",
            "Epoch 2/10, Loss: 10.7716\n",
            "Epoch 3/10, Loss: 8.4981\n",
            "Epoch 4/10, Loss: 6.5810\n",
            "Epoch 5/10, Loss: 6.1969\n",
            "Epoch 6/10, Loss: 7.9616\n",
            "Epoch 7/10, Loss: 12.3971\n",
            "Epoch 8/10, Loss: 12.4733\n",
            "Epoch 9/10, Loss: 9.3901\n",
            "Epoch 10/10, Loss: 5.9315\n",
            "     3 |       12 |      4 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f\n",
            "4\n",
            "[[11.32348667 48.01257934  5.          5.        ]\n",
            " [10.         48.31804932  8.23061234  5.        ]\n",
            " [43.67651333 46.98742066  6.          5.        ]\n",
            " [ 7.4722875  37.58814472  5.          7.80208415]]\n",
            "1e-05 5\n",
            "[11 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 17.0035\n",
            "Epoch 2/10, Loss: 13.0534\n",
            "Epoch 3/10, Loss: 8.4148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pymoo/operators/crossover/sbx.py:47: RuntimeWarning: invalid value encountered in power\n",
            "  betaq[mask] = np.power((rand * alpha), (1.0 / (eta + 1.0)))[mask]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Loss: 4.0281\n",
            "Epoch 5/10, Loss: 1.4864\n",
            "Epoch 6/10, Loss: 1.2816\n",
            "Epoch 7/10, Loss: 1.4832\n",
            "Epoch 8/10, Loss: 1.5573\n",
            "Epoch 9/10, Loss: 1.5009\n",
            "Epoch 10/10, Loss: 1.3830\n",
            "5.880139907956525e-09 5\n",
            "[10 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.7689\n",
            "Epoch 2/10, Loss: 27.6333\n",
            "Epoch 3/10, Loss: 27.5760\n",
            "Epoch 4/10, Loss: 27.5585\n",
            "Epoch 5/10, Loss: 27.5530\n",
            "Epoch 6/10, Loss: 27.5508\n",
            "Epoch 7/10, Loss: 27.5494\n",
            "Epoch 8/10, Loss: 27.5485\n",
            "Epoch 9/10, Loss: 27.5478\n",
            "Epoch 10/10, Loss: 27.5471\n",
            "1e-06 5\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 14.6961\n",
            "Epoch 2/10, Loss: 7.8404\n",
            "Epoch 3/10, Loss: 3.4561\n",
            "Epoch 4/10, Loss: 9.8610\n",
            "Epoch 5/10, Loss: 14.0471\n",
            "Epoch 6/10, Loss: 12.4407\n",
            "Epoch 7/10, Loss: 7.9137\n",
            "Epoch 8/10, Loss: 3.5361\n",
            "Epoch 9/10, Loss: 2.2788\n",
            "Epoch 10/10, Loss: 2.2096\n",
            "1e-05 7\n",
            "[ 7 38]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5540\n",
            "Epoch 2/10, Loss: 27.5500\n",
            "Epoch 3/10, Loss: 27.5491\n",
            "Epoch 4/10, Loss: 27.5487\n",
            "Epoch 5/10, Loss: 27.5484\n",
            "Epoch 6/10, Loss: 27.5481\n",
            "Epoch 7/10, Loss: 27.5478\n",
            "Epoch 8/10, Loss: 27.5474\n",
            "Epoch 9/10, Loss: 27.5471\n",
            "Epoch 10/10, Loss: 27.5468\n",
            "     4 |       16 |      4 |  0.000000E+00 |  0.000000E+00 |  1.5053468573 |         nadir\n",
            "5\n",
            "[[13.093314   47.42974856  5.96369749  5.        ]\n",
            " [13.2854057  46.94398716  5.85903013  5.        ]\n",
            " [43.67651333 48.0491465   5.05596176  5.        ]\n",
            " [43.67651333 48.0434335   5.03321405  5.        ]]\n",
            "1.087182639354538e-06 5\n",
            "[13 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 18.1721\n",
            "Epoch 2/10, Loss: 16.4916\n",
            "Epoch 3/10, Loss: 14.5821\n",
            "Epoch 4/10, Loss: 12.5581\n",
            "Epoch 5/10, Loss: 10.4263\n",
            "Epoch 6/10, Loss: 8.4886\n",
            "Epoch 7/10, Loss: 6.8514\n",
            "Epoch 8/10, Loss: 6.0927\n",
            "Epoch 9/10, Loss: 7.3106\n",
            "Epoch 10/10, Loss: 9.8022\n",
            "1.3834703853623626e-06 5\n",
            "[13 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 6.0488\n",
            "Epoch 2/10, Loss: 4.2379\n",
            "Epoch 3/10, Loss: 3.1870\n",
            "Epoch 4/10, Loss: 2.4260\n",
            "Epoch 5/10, Loss: 1.8751\n",
            "Epoch 6/10, Loss: 1.5182\n",
            "Epoch 7/10, Loss: 1.2831\n",
            "Epoch 8/10, Loss: 1.1300\n",
            "Epoch 9/10, Loss: 1.0509\n",
            "Epoch 10/10, Loss: 1.0259\n",
            "8.79099916619384e-06 5\n",
            "[44 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 19.7182\n",
            "Epoch 2/10, Loss: 17.0733\n",
            "Epoch 3/10, Loss: 14.3471\n",
            "Epoch 4/10, Loss: 10.3816\n",
            "Epoch 5/10, Loss: 4.6123\n",
            "Epoch 6/10, Loss: 2.2849\n",
            "Epoch 7/10, Loss: 2.1169\n",
            "Epoch 8/10, Loss: 1.5386\n",
            "Epoch 9/10, Loss: 1.2661\n",
            "Epoch 10/10, Loss: 2.4356\n",
            "9.263731394427225e-06 5\n",
            "[44 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 14.9534\n",
            "Epoch 2/10, Loss: 11.9541\n",
            "Epoch 3/10, Loss: 8.6626\n",
            "Epoch 4/10, Loss: 5.8628\n",
            "Epoch 5/10, Loss: 3.9072\n",
            "Epoch 6/10, Loss: 5.8937\n",
            "Epoch 7/10, Loss: 6.5698\n",
            "Epoch 8/10, Loss: 4.2598\n",
            "Epoch 9/10, Loss: 1.9252\n",
            "Epoch 10/10, Loss: 1.4093\n",
            "     5 |       20 |      3 |  0.000000E+00 |  0.000000E+00 |  0.1479043269 |         ideal\n",
            "6\n",
            "[[40.23721307 48.11017492  6.          5.        ]\n",
            " [44.33511358 46.96391344  5.03321405  5.        ]\n",
            " [43.69554433 46.93325858  5.03321405  5.        ]\n",
            " [43.69362149 49.35702068  6.          5.        ]]\n",
            "1e-06 5\n",
            "[40 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5993\n",
            "Epoch 2/10, Loss: 27.5629\n",
            "Epoch 3/10, Loss: 27.5623\n",
            "Epoch 4/10, Loss: 27.5615\n",
            "Epoch 5/10, Loss: 27.5613\n",
            "Epoch 6/10, Loss: 27.5611\n",
            "Epoch 7/10, Loss: 27.5607\n",
            "Epoch 8/10, Loss: 27.5604\n",
            "Epoch 9/10, Loss: 27.5599\n",
            "Epoch 10/10, Loss: 27.5595\n",
            "9.263731394427225e-06 5\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 20.8491\n",
            "Epoch 2/10, Loss: 17.8299\n",
            "Epoch 3/10, Loss: 12.6099\n",
            "Epoch 4/10, Loss: 7.1392\n",
            "Epoch 5/10, Loss: 3.7265\n",
            "Epoch 6/10, Loss: 14.4288\n",
            "Epoch 7/10, Loss: 14.9833\n",
            "Epoch 8/10, Loss: 7.9100\n",
            "Epoch 9/10, Loss: 3.0371\n",
            "Epoch 10/10, Loss: 2.2001\n",
            "9.263731394427225e-06 5\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 12.3995\n",
            "Epoch 2/10, Loss: 7.0341\n",
            "Epoch 3/10, Loss: 4.3039\n",
            "Epoch 4/10, Loss: 10.1167\n",
            "Epoch 5/10, Loss: 14.2018\n",
            "Epoch 6/10, Loss: 13.7587\n",
            "Epoch 7/10, Loss: 10.2742\n",
            "Epoch 8/10, Loss: 5.0795\n",
            "Epoch 9/10, Loss: 2.6096\n",
            "Epoch 10/10, Loss: 2.7538\n",
            "1e-06 5\n",
            "[44 49]\n",
            "51\n",
            "Epoch 1/10, Loss: 15.3016\n",
            "Epoch 2/10, Loss: 11.2085\n",
            "Epoch 3/10, Loss: 6.5192\n",
            "Epoch 4/10, Loss: 2.4990\n",
            "Epoch 5/10, Loss: 1.1337\n",
            "Epoch 6/10, Loss: 1.0216\n",
            "Epoch 7/10, Loss: 1.2097\n",
            "Epoch 8/10, Loss: 1.3210\n",
            "Epoch 9/10, Loss: 1.3616\n",
            "Epoch 10/10, Loss: 1.3358\n",
            "     6 |       24 |      4 |  0.000000E+00 |  0.000000E+00 |  0.0997102174 |         ideal\n",
            "7\n",
            "[[44.         49.98377145  6.          5.        ]\n",
            " [43.67651333 48.0434335   5.02808477  5.        ]\n",
            " [44.4167091  47.          5.01587857  5.        ]\n",
            " [44.42980357 45.98458569  6.04116853  5.        ]]\n",
            "1e-06 5\n",
            "[44 50]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5527\n",
            "Epoch 2/10, Loss: 27.5509\n",
            "Epoch 3/10, Loss: 27.5492\n",
            "Epoch 4/10, Loss: 27.5476\n",
            "Epoch 5/10, Loss: 27.5461\n",
            "Epoch 6/10, Loss: 27.5447\n",
            "Epoch 7/10, Loss: 27.5436\n",
            "Epoch 8/10, Loss: 27.5425\n",
            "Epoch 9/10, Loss: 27.5414\n",
            "Epoch 10/10, Loss: 27.5403\n",
            "9.373790181234904e-06 5\n",
            "[44 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 14.9078\n",
            "Epoch 2/10, Loss: 9.2933\n",
            "Epoch 3/10, Loss: 11.4159\n",
            "Epoch 4/10, Loss: 14.1292\n",
            "Epoch 5/10, Loss: 15.4550\n",
            "Epoch 6/10, Loss: 16.6224\n",
            "Epoch 7/10, Loss: 17.5028\n",
            "Epoch 8/10, Loss: 17.1890\n",
            "Epoch 9/10, Loss: 15.7530\n",
            "Epoch 10/10, Loss: 14.3327\n",
            "9.6409854656264e-06 5\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 20.1550\n",
            "Epoch 2/10, Loss: 18.2513\n",
            "Epoch 3/10, Loss: 16.0976\n",
            "Epoch 4/10, Loss: 14.9361\n",
            "Epoch 5/10, Loss: 12.9626\n",
            "Epoch 6/10, Loss: 9.9262\n",
            "Epoch 7/10, Loss: 7.8161\n",
            "Epoch 8/10, Loss: 5.3666\n",
            "Epoch 9/10, Loss: 2.7781\n",
            "Epoch 10/10, Loss: 3.0846\n",
            "9.095602348240166e-07 5\n",
            "[44 46]\n",
            "51\n",
            "Epoch 1/10, Loss: 5.2264\n",
            "Epoch 2/10, Loss: 6.7829\n",
            "Epoch 3/10, Loss: 7.9535\n",
            "Epoch 4/10, Loss: 5.9801\n",
            "Epoch 5/10, Loss: 2.1342\n",
            "Epoch 6/10, Loss: 1.4577\n",
            "Epoch 7/10, Loss: 1.4176\n",
            "Epoch 8/10, Loss: 2.0795\n",
            "Epoch 9/10, Loss: 1.9690\n",
            "Epoch 10/10, Loss: 1.2382\n",
            "     7 |       28 |      4 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f\n",
            "8\n",
            "[[39.84610896 46.93325858  5.03321405  5.        ]\n",
            " [43.67740461 46.70223857  7.09791876  5.        ]\n",
            " [41.46286125 47.41643998  5.03321405  5.        ]\n",
            " [44.         47.          5.9831683   5.        ]]\n",
            "9.263731394427225e-06 5\n",
            "[40 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5541\n",
            "Epoch 2/10, Loss: 27.5522\n",
            "Epoch 3/10, Loss: 27.5504\n",
            "Epoch 4/10, Loss: 27.5488\n",
            "Epoch 5/10, Loss: 27.5473\n",
            "Epoch 6/10, Loss: 27.5459\n",
            "Epoch 7/10, Loss: 27.5447\n",
            "Epoch 8/10, Loss: 27.5436\n",
            "Epoch 9/10, Loss: 27.5425\n",
            "Epoch 10/10, Loss: 27.5415\n",
            "7.981439726121673e-08 5\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 9.5135\n",
            "Epoch 2/10, Loss: 7.0407\n",
            "Epoch 3/10, Loss: 5.8156\n",
            "Epoch 4/10, Loss: 2.7766\n",
            "Epoch 5/10, Loss: 1.3196\n",
            "Epoch 6/10, Loss: 1.0397\n",
            "Epoch 7/10, Loss: 0.9541\n",
            "Epoch 8/10, Loss: 0.8858\n",
            "Epoch 9/10, Loss: 1.0080\n",
            "Epoch 10/10, Loss: 1.0844\n",
            "9.263731394427225e-06 5\n",
            "[41 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5543\n",
            "Epoch 2/10, Loss: 27.5525\n",
            "Epoch 3/10, Loss: 27.5511\n",
            "Epoch 4/10, Loss: 27.5498\n",
            "Epoch 5/10, Loss: 27.5487\n",
            "Epoch 6/10, Loss: 27.5477\n",
            "Epoch 7/10, Loss: 27.5468\n",
            "Epoch 8/10, Loss: 27.5459\n",
            "Epoch 9/10, Loss: 27.5450\n",
            "Epoch 10/10, Loss: 27.5441\n",
            "1.0395172410022359e-06 5\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 16.0491\n",
            "Epoch 2/10, Loss: 11.3848\n",
            "Epoch 3/10, Loss: 9.8635\n",
            "Epoch 4/10, Loss: 10.8273\n",
            "Epoch 5/10, Loss: 6.0392\n",
            "Epoch 6/10, Loss: 3.9447\n",
            "Epoch 7/10, Loss: 2.9646\n",
            "Epoch 8/10, Loss: 2.2743\n",
            "Epoch 9/10, Loss: 1.6734\n",
            "Epoch 10/10, Loss: 1.2898\n",
            "     8 |       32 |      4 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f\n",
            "9\n",
            "[[44.01561514 46.93325858  5.99303077  5.        ]\n",
            " [43.69567452 46.97667372  5.03321405  5.        ]\n",
            " [43.67992918 48.38705506  5.04579407  5.70722457]\n",
            " [43.67638314 44.206376    5.03321405  5.        ]]\n",
            "1.016176700379875e-06 5\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 9.5433\n",
            "Epoch 2/10, Loss: 5.2929\n",
            "Epoch 3/10, Loss: 2.1657\n",
            "Epoch 4/10, Loss: 1.6181\n",
            "Epoch 5/10, Loss: 5.7988\n",
            "Epoch 6/10, Loss: 5.8095\n",
            "Epoch 7/10, Loss: 3.4191\n",
            "Epoch 8/10, Loss: 1.4900\n",
            "Epoch 9/10, Loss: 1.2135\n",
            "Epoch 10/10, Loss: 1.3946\n",
            "9.263731394427225e-06 5\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 8.8894\n",
            "Epoch 2/10, Loss: 8.9921\n",
            "Epoch 3/10, Loss: 6.9650\n",
            "Epoch 4/10, Loss: 3.5827\n",
            "Epoch 5/10, Loss: 1.7309\n",
            "Epoch 6/10, Loss: 1.4615\n",
            "Epoch 7/10, Loss: 1.4966\n",
            "Epoch 8/10, Loss: 1.4144\n",
            "Epoch 9/10, Loss: 1.1668\n",
            "Epoch 10/10, Loss: 1.0675\n",
            "8.99924202960683e-06 5\n",
            "[44 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5028\n",
            "Epoch 2/10, Loss: 27.4780\n",
            "Epoch 3/10, Loss: 27.3116\n",
            "Epoch 4/10, Loss: 26.4130\n",
            "Epoch 5/10, Loss: 24.7871\n",
            "Epoch 6/10, Loss: 22.2004\n",
            "Epoch 7/10, Loss: 19.5832\n",
            "Epoch 8/10, Loss: 13.6661\n",
            "Epoch 9/10, Loss: 8.4506\n",
            "Epoch 10/10, Loss: 3.6388\n",
            "9.263731394427225e-06 5\n",
            "[44 44]\n",
            "51\n",
            "Epoch 1/10, Loss: 27.5501\n",
            "Epoch 2/10, Loss: 27.5492\n",
            "Epoch 3/10, Loss: 27.5484\n",
            "Epoch 4/10, Loss: 27.5476\n",
            "Epoch 5/10, Loss: 27.5470\n",
            "Epoch 6/10, Loss: 27.5463\n",
            "Epoch 7/10, Loss: 27.5457\n",
            "Epoch 8/10, Loss: 27.5450\n",
            "Epoch 9/10, Loss: 27.5443\n",
            "Epoch 10/10, Loss: 27.5436\n",
            "     9 |       36 |      4 |  0.000000E+00 |  0.000000E+00 |  0.000000E+00 |             f\n",
            "10\n",
            "[[43.69554433 48.07045933  5.03321405  5.        ]\n",
            " [43.93617136 48.0434335   5.03321405  5.        ]\n",
            " [41.63313868 46.52485466  5.0094807   5.        ]\n",
            " [44.         47.          6.97488433  6.75938655]]\n",
            "9.263731394427225e-06 5\n",
            "[44 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 13.5057\n",
            "Epoch 2/10, Loss: 9.6020\n",
            "Epoch 3/10, Loss: 8.0524\n",
            "Epoch 4/10, Loss: 6.3767\n",
            "Epoch 5/10, Loss: 4.8830\n",
            "Epoch 6/10, Loss: 3.8445\n",
            "Epoch 7/10, Loss: 2.9614\n",
            "Epoch 8/10, Loss: 2.3244\n",
            "Epoch 9/10, Loss: 2.0526\n",
            "Epoch 10/10, Loss: 1.9909\n",
            "9.263731394427225e-06 5\n",
            "[44 48]\n",
            "51\n",
            "Epoch 1/10, Loss: 9.7234\n",
            "Epoch 2/10, Loss: 7.5057\n",
            "Epoch 3/10, Loss: 5.4907\n",
            "Epoch 4/10, Loss: 4.2932\n",
            "Epoch 5/10, Loss: 4.4278\n",
            "Epoch 6/10, Loss: 4.6908\n",
            "Epoch 7/10, Loss: 3.7084\n",
            "Epoch 8/10, Loss: 1.7974\n",
            "Epoch 9/10, Loss: 0.9416\n",
            "Epoch 10/10, Loss: 1.0241\n",
            "9.784064374707945e-06 5\n",
            "[42 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 19.5497\n",
            "Epoch 2/10, Loss: 16.9372\n",
            "Epoch 3/10, Loss: 13.0964\n",
            "Epoch 4/10, Loss: 8.7641\n",
            "Epoch 5/10, Loss: 5.6382\n",
            "Epoch 6/10, Loss: 11.0292\n",
            "Epoch 7/10, Loss: 14.5631\n",
            "Epoch 8/10, Loss: 14.7610\n",
            "Epoch 9/10, Loss: 12.5837\n",
            "Epoch 10/10, Loss: 7.1949\n",
            "1.0595358741337517e-07 6\n",
            "[44 47]\n",
            "51\n",
            "Epoch 1/10, Loss: 17.0241\n",
            "Epoch 2/10, Loss: 19.9173\n",
            "Epoch 3/10, Loss: 22.3568\n",
            "Epoch 4/10, Loss: 19.5524\n",
            "Epoch 5/10, Loss: 12.0514\n",
            "Epoch 6/10, Loss: 6.9420\n",
            "Epoch 7/10, Loss: 4.9931\n",
            "Epoch 8/10, Loss: 3.2221\n",
            "Epoch 9/10, Loss: 2.1994\n",
            "Epoch 10/10, Loss: 1.8841\n",
            "    10 |       40 |      4 |  0.000000E+00 |  0.000000E+00 |  0.2939393602 |         ideal\n",
            "\n",
            "Best G for FGSM found: [[-0.02966044]\n",
            " [-0.02966044]\n",
            " [-0.02966044]\n",
            " [-0.18281356]]\n",
            "\n",
            "Best solution found: [[0.42966044 0.0284912  0.03496442 0.10570237]\n",
            " [0.42966044 0.01986588 0.04975676 0.11682893]\n",
            " [0.42966044 0.05888852 0.07715401 0.07093184]\n",
            " [0.58281356 0.05747696 0.1038394  0.0844228 ]]\n",
            "\n",
            "Best architecture found: [[43.67651333 48.0434335   5.03321405  5.        ]\n",
            " [43.69554433 46.93325858  5.03321405  5.        ]\n",
            " [41.63313868 46.52485466  5.0094807   5.        ]\n",
            " [44.         47.          6.          5.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below code Envolved with weight search space : **"
      ],
      "metadata": {
        "id": "e5q_3fkyUBaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mutate(ffn, mutation_rate=0.1, mutation_strength=0.01):\n",
        "    parameters = ffn.get_parameters()\n",
        "    for i in range(len(parameters)):\n",
        "        if np.random.rand() < mutation_rate:\n",
        "            noise = torch.randn_like(parameters[i]) * mutation_strength\n",
        "            parameters[i] += noise\n",
        "    ffn.set_parameters(parameters)\n"
      ],
      "metadata": {
        "id": "K5B4csWqyZF5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population_size = res.X.shape[0]\n",
        "population_structures = []\n",
        "for i in range(population_size):\n",
        "    population_structures.append(res.X[0].tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "G4iEzVi7yZLQ"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "# Train 5 initial models on the COMPAS dataset\n",
        "trained_models = []\n",
        "for _ in population_structures:\n",
        "\n",
        "    l = []\n",
        "    for i in range(len(_)-2):\n",
        "      l.append(int(_[i]))\n",
        "\n",
        "\n",
        "    model = FFN(input_size, l, 2)\n",
        "    adversarial_train(model, X_train_tensor, y_train_tensor, optim.Adam(model.parameters(), lr=0.001), 'cpu', epsilon=0.2, attack_type='fgsm')\n",
        "    #train_model(model, X_train_tensor, y_train_tensor)  # Assume this function trains the model\n",
        "    trained_models.append(model)\n",
        "\n",
        "# Clone and mutate to complete the population\n",
        "\n",
        "population = []\n",
        "for _ in range(population_size):\n",
        "    base_model = deepcopy(trained_models[np.random.randint(population_size)])\n",
        "    mutate(base_model)  # Apply slight mutation for diversity\n",
        "    population.append(base_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9uAbxA-yZQ7",
        "outputId": "b1bf6db6-56a7-40ae-e5e5-1686e2a9845d"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 18.2089\n",
            "Epoch 2/10, Loss: 14.6884\n",
            "Epoch 3/10, Loss: 10.4617\n",
            "Epoch 4/10, Loss: 8.5527\n",
            "Epoch 5/10, Loss: 5.3944\n",
            "Epoch 6/10, Loss: 3.8625\n",
            "Epoch 7/10, Loss: 2.4024\n",
            "Epoch 8/10, Loss: 2.8767\n",
            "Epoch 9/10, Loss: 1.4216\n",
            "Epoch 10/10, Loss: 1.1445\n",
            "Epoch 1/10, Loss: 5.2481\n",
            "Epoch 2/10, Loss: 15.8512\n",
            "Epoch 3/10, Loss: 16.9626\n",
            "Epoch 4/10, Loss: 16.4212\n",
            "Epoch 5/10, Loss: 15.0354\n",
            "Epoch 6/10, Loss: 12.5992\n",
            "Epoch 7/10, Loss: 8.9510\n",
            "Epoch 8/10, Loss: 5.1993\n",
            "Epoch 9/10, Loss: 4.2400\n",
            "Epoch 10/10, Loss: 4.4611\n",
            "Epoch 1/10, Loss: 4.0013\n",
            "Epoch 2/10, Loss: 4.2940\n",
            "Epoch 3/10, Loss: 7.3669\n",
            "Epoch 4/10, Loss: 3.1384\n",
            "Epoch 5/10, Loss: 0.9733\n",
            "Epoch 6/10, Loss: 1.1895\n",
            "Epoch 7/10, Loss: 1.3131\n",
            "Epoch 8/10, Loss: 1.1026\n",
            "Epoch 9/10, Loss: 0.8833\n",
            "Epoch 10/10, Loss: 0.9559\n",
            "Epoch 1/10, Loss: 5.9092\n",
            "Epoch 2/10, Loss: 3.1716\n",
            "Epoch 3/10, Loss: 9.2428\n",
            "Epoch 4/10, Loss: 6.6872\n",
            "Epoch 5/10, Loss: 2.2299\n",
            "Epoch 6/10, Loss: 1.2813\n",
            "Epoch 7/10, Loss: 1.6863\n",
            "Epoch 8/10, Loss: 1.7675\n",
            "Epoch 9/10, Loss: 1.5249\n",
            "Epoch 10/10, Loss: 1.2226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[sum(param.numel() for param in population[i].get_parameters()) for i in range(len(population))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivjzhQfM7SpL",
        "outputId": "b11bb212-2e4f-4709-aba8-2d84c3f0a579"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4397, 4397, 4397, 4397]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "population[0].parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dF4O4z66W8R",
        "outputId": "faa33cee-4bc9-4fc9-b3e8-07c8ab36313a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7e76bf3a4200>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, param in enumerate(population[0].get_parameters()):\n",
        "  print(i)\n",
        "  print(param[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z82p5IWpyZVK",
        "outputId": "aacc6a78-1268-4927-d797-7b9c66811e7a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "torch.Size([97])\n",
            "1\n",
            "torch.Size([])\n",
            "2\n",
            "torch.Size([6])\n",
            "3\n",
            "torch.Size([])\n",
            "4\n",
            "torch.Size([7])\n",
            "5\n",
            "torch.Size([])\n",
            "6\n",
            "torch.Size([6])\n",
            "7\n",
            "torch.Size([])\n",
            "8\n",
            "torch.Size([8])\n",
            "9\n",
            "torch.Size([])\n",
            "10\n",
            "torch.Size([6])\n",
            "11\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.core.callback import Callback\n",
        "\n",
        "\n",
        "# Define the optimization problem\n",
        "class FFNOptimizationProblem(Problem):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "\n",
        "        # Flatten the parameters to create a single vector of variables\n",
        "        self.original_params = model.get_parameters()\n",
        "        self.param_shapes = [param.shape for param in self.original_params]\n",
        "        self.num_vars = sum(param.numel() for param in self.original_params)\n",
        "\n",
        "        super().__init__(n_var=self.num_vars, n_obj=5, n_constr=0, xl=-1.0, xu=1.0)\n",
        "\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        adversarial_accuracy_PGD = np.zeros(x.shape[0])\n",
        "        adversarial_accuracy_FGSM = np.zeros(x.shape[0])\n",
        "        equalized_odds_gender = np.zeros(x.shape[0])\n",
        "        equalized_odds_race_Black = np.zeros(x.shape[0])\n",
        "        equalized_odds_race_White = np.zeros(x.shape[0])\n",
        "        # Reshape the flat vector back into the model parameters\n",
        "        for i in range(x.shape[0]):  # Iterate over each individual in the population\n",
        "            params = self._reshape_params(x[i])\n",
        "            self.model.set_parameters(params)\n",
        "            model = self.model\n",
        "            accuracy_pgd = adversarial_attack_accuracy(model, X_test_tensor, y_test_tensor, 'PGD')\n",
        "            accuracy_fgsm = adversarial_attack_accuracy(model, X_test_tensor, y_test_tensor, 'FGSM')\n",
        "            tpr_diff_gender, fpr_diff_gender = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, X_test[sensetive_features[fairness_to_select][0]])\n",
        "            tpr_diff_race_Black, fpr_diff_race_Black = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, X_test[sensetive_features[fairness_to_select][1]])\n",
        "            tpr_diff_race_White, fpr_diff_race_White = compute_equalized_odds_difference(model, X_test_tensor, y_test_tensor, X_test[sensetive_features[fairness_to_select][2]])\n",
        "\n",
        "            equalized_odd_gender = (tpr_diff_gender + fpr_diff_gender) / 2\n",
        "            equalized_odd_race_Black = (tpr_diff_race_Black + fpr_diff_race_Black) / 2\n",
        "            equalized_odd_race_White = (tpr_diff_race_White + fpr_diff_race_White) / 2\n",
        "\n",
        "            adversarial_accuracy_PGD[i] = accuracy_pgd\n",
        "            adversarial_accuracy_FGSM[i] = accuracy_fgsm\n",
        "\n",
        "            equalized_odds_gender[i] = equalized_odd_gender\n",
        "            equalized_odds_race_Black[i] = equalized_odd_race_Black\n",
        "            equalized_odds_race_White[i] = equalized_odd_race_White\n",
        "\n",
        "        out[\"F\"] = np.column_stack([adversarial_accuracy_PGD, adversarial_accuracy_FGSM, equalized_odds_gender, equalized_odds_race_Black, equalized_odds_race_White])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _reshape_params(self, x):\n",
        "        params = []\n",
        "        index = 0\n",
        "        for shape in self.param_shapes:\n",
        "            size = np.prod(shape)\n",
        "            params.append(torch.tensor(x[index:index + size].reshape(shape), dtype=torch.float32))\n",
        "            index += size\n",
        "        return params\n",
        "\n",
        "\n",
        "model = population[0]\n",
        "\n",
        "\n",
        "# Load pretrained models (example)\n",
        "pretrained_models = population\n",
        "# Assume pretrained_models are already trained and parameters are set\n",
        "\n",
        "# Flatten parameters of pretrained models to use as initial population\n",
        "initial_population = []\n",
        "expected_size = sum(p.numel() for p in pretrained_models[0].get_parameters())\n",
        "for pretrained_model in pretrained_models:\n",
        "\n",
        "    params = pretrained_model.get_parameters()\n",
        "    flat_params = np.concatenate([p.detach().cpu().numpy().flatten() for p in params])\n",
        "    print(f\"Model {i} flattened parameter shape: {flat_params.shape}\")\n",
        "    if flat_params.shape[0] != expected_size:\n",
        "        print(f\"Model {i} has an inconsistent shape: {flat_params.shape}\")\n",
        "    initial_population.append(flat_params)\n",
        "# Convert initial population to a numpy array\n",
        "initial_population = np.stack(initial_population)\n",
        "\n",
        "# Define the problem\n",
        "problem = FFNOptimizationProblem(model)\n",
        "\n",
        "# Initialize the algorithm with the initial population\n",
        "algorithm = NSGA2(pop_size=4, sampling=initial_population)\n",
        "\n",
        "# Run the optimization\n",
        "res = minimize(problem, algorithm, ('n_gen', 5), verbose=True)\n",
        "\n",
        "print(\"Best solution found: %s\" % res.F[0])\n",
        "#print(\"Best variables found: %s\" % res.X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OwukPWMyJ2A",
        "outputId": "56f3bc51-15b9-4789-cbf0-3ea99a6e7f5f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 flattened parameter shape: (4397,)\n",
            "Model 1 flattened parameter shape: (4397,)\n",
            "Model 1 flattened parameter shape: (4397,)\n",
            "Model 1 flattened parameter shape: (4397,)\n",
            "==========================================================\n",
            "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
            "==========================================================\n",
            "     1 |        3 |      3 |             - |             -\n",
            "     2 |        7 |      4 |  0.8351783901 |         ideal\n",
            "     3 |       11 |      4 |  0.3564867807 |         ideal\n",
            "     4 |       15 |      4 |  0.7975205099 |         ideal\n",
            "     5 |       19 |      4 |  0.2054541450 |             f\n",
            "Best solution found: [5.70339561e-01 5.70339561e-01 4.19111486e-04 6.83994556e-04\n",
            " 3.47705150e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQpLZDpbH4af",
        "outputId": "29f2c45a-c7e7-4fc6-e360-8a109dc3957b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    hidden_sizes = [trial.suggest_int('n_units_l1', 5, 50),\n",
        "                    trial.suggest_int('n_units_l2', 5, 50)]\n",
        "\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
        "\n",
        "    # Define the model\n",
        "    model = FFN(input_size=input_size, hidden_sizes=hidden_sizes, output_size=2)\n",
        "\n",
        "\n",
        "    train_model(model, X_train_tensor, y_train_tensor)\n",
        "    adversarial_train(model, X_train_tensor, y_train_tensor, optim.Adam(model.parameters(), lr=learning_rate), 'cpu', epsilon=0.2, attack_type='fgsm')\n",
        "    # Evaluation\n",
        "    accuracy = adversarial_attack_accuracy(model, X_test_tensor, y_test_tensor, 'FGSM')\n",
        "    return accuracy\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "print(\"  Params: \")\n",
        "tt = []\n",
        "for key, value in trial.params.items():\n",
        "    tt.append(value)\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "lerr = tt[-1]\n",
        "tt = tt[: -1]"
      ],
      "metadata": {
        "id": "k_aXLTiYyJ8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87540a99-b6dd-4ab1-900c-af4592128154"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:41:28,307] A new study created in memory with name: no-name-c16ae3c3-bf26-4290-979f-09f67dcdd1d8\n",
            "<ipython-input-104-22c42653ff17>:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 9848.2955\n",
            "Epoch 2/10, Loss: 9854.2614\n",
            "Epoch 3/10, Loss: 9854.2614\n",
            "Epoch 4/10, Loss: 9848.2955\n",
            "Epoch 5/10, Loss: 9836.3636\n",
            "Epoch 6/10, Loss: 9854.2614\n",
            "Epoch 7/10, Loss: 9860.2273\n",
            "Epoch 8/10, Loss: 9848.2955\n",
            "Epoch 9/10, Loss: 9830.3977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:41:43,373] Trial 0 finished with value: 0.429660439491272 and parameters: {'n_units_l1': 19, 'n_units_l2': 24, 'learning_rate': 0.002264229580328559}. Best is trial 0 with value: 0.429660439491272.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 9836.3636\n",
            "Epoch 1/10, Loss: 27.5648\n",
            "Epoch 2/10, Loss: 27.5623\n",
            "Epoch 3/10, Loss: 27.5602\n",
            "Epoch 4/10, Loss: 27.5585\n",
            "Epoch 5/10, Loss: 27.5570\n",
            "Epoch 6/10, Loss: 27.5484\n",
            "Epoch 7/10, Loss: 27.3186\n",
            "Epoch 8/10, Loss: 21.9705\n",
            "Epoch 9/10, Loss: 12.4285\n",
            "Epoch 10/10, Loss: 7.9320\n",
            "Epoch 1/10, Loss: 9836.3859\n",
            "Epoch 2/10, Loss: 9842.3295\n",
            "Epoch 3/10, Loss: 9848.2955\n",
            "Epoch 4/10, Loss: 9842.3295\n",
            "Epoch 5/10, Loss: 9848.2955\n",
            "Epoch 6/10, Loss: 9836.3636\n",
            "Epoch 7/10, Loss: 9842.3295\n",
            "Epoch 8/10, Loss: 9854.2614\n",
            "Epoch 9/10, Loss: 9818.4659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:41:58,351] Trial 1 finished with value: 0.429660439491272 and parameters: {'n_units_l1': 11, 'n_units_l2': 5, 'learning_rate': 3.782291530871839e-05}. Best is trial 0 with value: 0.429660439491272.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 9848.2955\n",
            "Epoch 1/10, Loss: 27.5557\n",
            "Epoch 2/10, Loss: 27.5557\n",
            "Epoch 3/10, Loss: 27.5557\n",
            "Epoch 4/10, Loss: 27.5557\n",
            "Epoch 5/10, Loss: 27.5556\n",
            "Epoch 6/10, Loss: 27.5556\n",
            "Epoch 7/10, Loss: 27.5556\n",
            "Epoch 8/10, Loss: 27.5556\n",
            "Epoch 9/10, Loss: 27.5556\n",
            "Epoch 10/10, Loss: 27.5555\n",
            "Epoch 1/10, Loss: 9848.2974\n",
            "Epoch 2/10, Loss: 9836.3636\n",
            "Epoch 3/10, Loss: 9854.2614\n",
            "Epoch 4/10, Loss: 9854.2614\n",
            "Epoch 5/10, Loss: 9854.2614\n",
            "Epoch 6/10, Loss: 9866.1932\n",
            "Epoch 7/10, Loss: 9848.2955\n",
            "Epoch 8/10, Loss: 9836.3636\n",
            "Epoch 9/10, Loss: 9848.2955\n",
            "Epoch 10/10, Loss: 9848.2955\n",
            "Epoch 1/10, Loss: 27.5532\n",
            "Epoch 2/10, Loss: 27.5531\n",
            "Epoch 3/10, Loss: 27.5531\n",
            "Epoch 4/10, Loss: 27.5530\n",
            "Epoch 5/10, Loss: 27.5529\n",
            "Epoch 6/10, Loss: 27.5528\n",
            "Epoch 7/10, Loss: 27.5527\n",
            "Epoch 8/10, Loss: 27.5526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:42:14,153] Trial 2 finished with value: 0.4206514060497284 and parameters: {'n_units_l1': 28, 'n_units_l2': 41, 'learning_rate': 8.936189992224114e-05}. Best is trial 0 with value: 0.429660439491272.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Loss: 27.5525\n",
            "Epoch 10/10, Loss: 27.5525\n",
            "Epoch 1/10, Loss: 501.8130\n",
            "Epoch 2/10, Loss: 83.5823\n",
            "Epoch 3/10, Loss: 80.4467\n",
            "Epoch 4/10, Loss: 59.0261\n",
            "Epoch 5/10, Loss: 60.3253\n",
            "Epoch 6/10, Loss: 38.6649\n",
            "Epoch 7/10, Loss: 39.5425\n",
            "Epoch 8/10, Loss: 37.5998\n",
            "Epoch 9/10, Loss: 35.4046\n",
            "Epoch 10/10, Loss: 36.3626\n",
            "Epoch 1/10, Loss: 0.4872\n",
            "Epoch 2/10, Loss: 0.6464\n",
            "Epoch 3/10, Loss: 0.5114\n",
            "Epoch 4/10, Loss: 0.4287\n",
            "Epoch 5/10, Loss: 0.5083\n",
            "Epoch 6/10, Loss: 0.4959\n",
            "Epoch 7/10, Loss: 0.4320\n",
            "Epoch 8/10, Loss: 0.4315\n",
            "Epoch 9/10, Loss: 0.4583\n",
            "Epoch 10/10, Loss: 0.4722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:42:29,527] Trial 3 finished with value: 0.429660439491272 and parameters: {'n_units_l1': 33, 'n_units_l2': 30, 'learning_rate': 0.0009588409452994956}. Best is trial 0 with value: 0.429660439491272.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 450.6188\n",
            "Epoch 2/10, Loss: 48.5311\n",
            "Epoch 3/10, Loss: 35.1861\n",
            "Epoch 4/10, Loss: 29.2503\n",
            "Epoch 5/10, Loss: 26.9303\n",
            "Epoch 6/10, Loss: 25.4364\n",
            "Epoch 7/10, Loss: 24.2517\n",
            "Epoch 8/10, Loss: 24.3105\n",
            "Epoch 9/10, Loss: 25.3321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:42:44,472] Trial 4 finished with value: 0.429660439491272 and parameters: {'n_units_l1': 11, 'n_units_l2': 32, 'learning_rate': 1.3864595140624658e-05}. Best is trial 0 with value: 0.429660439491272.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 22.7216\n",
            "Epoch 1/10, Loss: 0.4208\n",
            "Epoch 2/10, Loss: 0.4199\n",
            "Epoch 3/10, Loss: 0.4191\n",
            "Epoch 4/10, Loss: 0.4183\n",
            "Epoch 5/10, Loss: 0.4176\n",
            "Epoch 6/10, Loss: 0.4169\n",
            "Epoch 7/10, Loss: 0.4163\n",
            "Epoch 8/10, Loss: 0.4157\n",
            "Epoch 9/10, Loss: 0.4152\n",
            "Epoch 10/10, Loss: 0.4147\n",
            "Epoch 1/10, Loss: 9854.5053\n",
            "Epoch 2/10, Loss: 9848.2955\n",
            "Epoch 3/10, Loss: 9848.2955\n",
            "Epoch 4/10, Loss: 9848.2955\n",
            "Epoch 5/10, Loss: 9830.3977\n",
            "Epoch 6/10, Loss: 9836.3636\n",
            "Epoch 7/10, Loss: 9872.1591\n",
            "Epoch 8/10, Loss: 9854.2614\n",
            "Epoch 9/10, Loss: 9836.3636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:42:59,506] Trial 5 finished with value: 0.4442134499549866 and parameters: {'n_units_l1': 12, 'n_units_l2': 18, 'learning_rate': 0.004689196958165609}. Best is trial 5 with value: 0.4442134499549866.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 9848.2955\n",
            "Epoch 1/10, Loss: 27.5733\n",
            "Epoch 2/10, Loss: 27.5667\n",
            "Epoch 3/10, Loss: 27.5603\n",
            "Epoch 4/10, Loss: 27.5511\n",
            "Epoch 5/10, Loss: 27.5328\n",
            "Epoch 6/10, Loss: 27.5055\n",
            "Epoch 7/10, Loss: 27.4948\n",
            "Epoch 8/10, Loss: 27.4858\n",
            "Epoch 9/10, Loss: 27.4293\n",
            "Epoch 10/10, Loss: 27.2968\n",
            "Epoch 1/10, Loss: 1298.5515\n",
            "Epoch 2/10, Loss: 76.3970\n",
            "Epoch 3/10, Loss: 48.7124\n",
            "Epoch 4/10, Loss: 38.0011\n",
            "Epoch 5/10, Loss: 42.9780\n",
            "Epoch 6/10, Loss: 32.7629\n",
            "Epoch 7/10, Loss: 32.2111\n",
            "Epoch 8/10, Loss: 32.2143\n",
            "Epoch 9/10, Loss: 29.9275\n",
            "Epoch 10/10, Loss: 29.2318\n",
            "Epoch 1/10, Loss: 0.4758\n",
            "Epoch 2/10, Loss: 0.7767\n",
            "Epoch 3/10, Loss: 0.4410\n",
            "Epoch 4/10, Loss: 0.4829\n",
            "Epoch 5/10, Loss: 0.5636\n",
            "Epoch 6/10, Loss: 0.5677\n",
            "Epoch 7/10, Loss: 0.5096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:43:15,637] Trial 6 finished with value: 0.429660439491272 and parameters: {'n_units_l1': 24, 'n_units_l2': 34, 'learning_rate': 0.0013766944945430108}. Best is trial 5 with value: 0.4442134499549866.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Loss: 0.4504\n",
            "Epoch 9/10, Loss: 0.4511\n",
            "Epoch 10/10, Loss: 0.4877\n",
            "Epoch 1/10, Loss: 202.7245\n",
            "Epoch 2/10, Loss: 55.7787\n",
            "Epoch 3/10, Loss: 50.9619\n",
            "Epoch 4/10, Loss: 42.0541\n",
            "Epoch 5/10, Loss: 31.0516\n",
            "Epoch 6/10, Loss: 35.0116\n",
            "Epoch 7/10, Loss: 32.9516\n",
            "Epoch 8/10, Loss: 34.9464\n",
            "Epoch 9/10, Loss: 29.1276\n",
            "Epoch 10/10, Loss: 34.7963\n",
            "Epoch 1/10, Loss: 0.4222\n",
            "Epoch 2/10, Loss: 0.4201\n",
            "Epoch 3/10, Loss: 0.4204\n",
            "Epoch 4/10, Loss: 0.4185\n",
            "Epoch 5/10, Loss: 0.4171\n",
            "Epoch 6/10, Loss: 0.4170\n",
            "Epoch 7/10, Loss: 0.4169\n",
            "Epoch 8/10, Loss: 0.4161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:43:31,067] Trial 7 finished with value: 0.429660439491272 and parameters: {'n_units_l1': 39, 'n_units_l2': 36, 'learning_rate': 0.00013291505305367923}. Best is trial 5 with value: 0.4442134499549866.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Loss: 0.4152\n",
            "Epoch 10/10, Loss: 0.4148\n",
            "Epoch 1/10, Loss: 1745.3432\n",
            "Epoch 2/10, Loss: 55.4775\n",
            "Epoch 3/10, Loss: 50.5195\n",
            "Epoch 4/10, Loss: 45.9385\n",
            "Epoch 5/10, Loss: 47.2589\n",
            "Epoch 6/10, Loss: 35.8309\n",
            "Epoch 7/10, Loss: 36.1129\n",
            "Epoch 8/10, Loss: 33.2118\n",
            "Epoch 9/10, Loss: 30.0671\n",
            "Epoch 10/10, Loss: 23.7860\n",
            "Epoch 1/10, Loss: 0.4059\n",
            "Epoch 2/10, Loss: 1.0123\n",
            "Epoch 3/10, Loss: 0.4175\n",
            "Epoch 4/10, Loss: 0.7028\n",
            "Epoch 5/10, Loss: 0.5465\n",
            "Epoch 6/10, Loss: 0.4073\n",
            "Epoch 7/10, Loss: 0.4331\n",
            "Epoch 8/10, Loss: 0.4987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:43:46,541] Trial 8 finished with value: 0.429660439491272 and parameters: {'n_units_l1': 42, 'n_units_l2': 39, 'learning_rate': 0.0017280217925293908}. Best is trial 5 with value: 0.4442134499549866.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Loss: 0.5264\n",
            "Epoch 10/10, Loss: 0.4988\n",
            "Epoch 1/10, Loss: 256.4975\n",
            "Epoch 2/10, Loss: 39.0347\n",
            "Epoch 3/10, Loss: 30.0177\n",
            "Epoch 4/10, Loss: 30.3530\n",
            "Epoch 5/10, Loss: 24.8702\n",
            "Epoch 6/10, Loss: 24.2013\n",
            "Epoch 7/10, Loss: 22.6400\n",
            "Epoch 8/10, Loss: 24.7529\n",
            "Epoch 9/10, Loss: 21.7610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-15 02:44:01,794] Trial 9 finished with value: 0.429660439491272 and parameters: {'n_units_l1': 11, 'n_units_l2': 12, 'learning_rate': 0.00020228582828626333}. Best is trial 5 with value: 0.4442134499549866.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 24.7731\n",
            "Epoch 1/10, Loss: 0.4011\n",
            "Epoch 2/10, Loss: 0.3957\n",
            "Epoch 3/10, Loss: 0.3974\n",
            "Epoch 4/10, Loss: 0.3982\n",
            "Epoch 5/10, Loss: 0.3965\n",
            "Epoch 6/10, Loss: 0.3952\n",
            "Epoch 7/10, Loss: 0.3953\n",
            "Epoch 8/10, Loss: 0.3959\n",
            "Epoch 9/10, Loss: 0.3962\n",
            "Epoch 10/10, Loss: 0.3957\n",
            "Best trial:\n",
            "  Value: 0.4442134499549866\n",
            "  Params: \n",
            "    n_units_l1: 12\n",
            "    n_units_l2: 18\n",
            "    learning_rate: 0.004689196958165609\n"
          ]
        }
      ]
    }
  ]
}